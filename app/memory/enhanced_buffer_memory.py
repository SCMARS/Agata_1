"""
–£–ª—É—á—à–µ–Ω–Ω–∞—è BufferMemory —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π —Å—É–º–º–∞—Ä–∏–∑–∞—Ü–∏–∏, —ç–º–æ—Ü–∏–π –∏ –ø–æ–≤–µ–¥–µ–Ω–∏—è
–ò–Ω—Ç–µ–≥—Ä–∏—Ä—É–µ—Ç—Å—è —Å —Å—É—â–µ—Å—Ç–≤—É—é—â–µ–π –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–æ–π –±–µ–∑ —Ö–∞—Ä–¥–∫–æ–¥–∞
"""
import json
import logging
import asyncio
from typing import List, Dict, Any, Optional, Union
from datetime import datetime, timedelta
from enum import Enum

# –ò–º–ø–æ—Ä—Ç—ã –¥–ª—è LLM
try:
    from langchain_openai import ChatOpenAI
    from langchain_core.messages import SystemMessage
    LANGCHAIN_AVAILABLE = True
except ImportError:
    LANGCHAIN_AVAILABLE = False
    print("‚ö†Ô∏è LangChain not available for enhanced memory")

# –ò–º–ø–æ—Ä—Ç—ã –ø—Ä–æ–µ–∫—Ç–∞
from .base import MemoryAdapter, Message, MemoryContext
try:
    from ..config.production_config_manager import get_config
    CONFIG_MANAGER_AVAILABLE = True
except ImportError:
    CONFIG_MANAGER_AVAILABLE = False
    print("‚ö†Ô∏è ProductionConfigManager not available, using fallback")


class EmotionTag(Enum):
    """–¢–µ–≥–∏ —ç–º–æ—Ü–∏–π –¥–ª—è —Å–æ–æ–±—â–µ–Ω–∏–π"""
    NEUTRAL = "neutral"
    HAPPY = "happy"
    SAD = "sad"
    EXCITED = "excited"
    WORRIED = "worried"
    CONFUSED = "confused"
    GRATEFUL = "grateful"
    FRUSTRATED = "frustrated"


class BehaviorTag(Enum):
    """–¢–µ–≥–∏ –ø–æ–≤–µ–¥–µ–Ω–∏—è –¥–ª—è —Å—Ç—Ä–∞—Ç–µ–≥–∏–π"""
    CARE = "care"
    PLAYFUL = "playful"
    RESERVED = "reserved"
    PROFESSIONAL = "professional"
    FRIENDLY = "friendly"
    SUPPORTIVE = "supportive"


class EnhancedMessage(Message):
    """–†–∞—Å—à–∏—Ä–µ–Ω–Ω–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ —Å —ç–º–æ—Ü–∏—è–º–∏ –∏ –ø–æ–≤–µ–¥–µ–Ω–∏–µ–º"""
    
    def __init__(self, role: str, content: str, timestamp: datetime, 
                 metadata: Dict[str, Any] = None,
                 emotion_tag: Optional[EmotionTag] = None,
                 behavior_tag: Optional[BehaviorTag] = None,
                 importance_score: float = 0.5,
                 topics: List[str] = None):
        super().__init__(role, content, timestamp, metadata)
        self.emotion_tag = emotion_tag
        self.behavior_tag = behavior_tag
        self.importance_score = importance_score
        self.topics = topics or []
    
    def to_dict(self) -> Dict[str, Any]:
        """–ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –≤ —Å–ª–æ–≤–∞—Ä—å"""
        return {
            'role': self.role,
            'content': self.content,
            'timestamp': self.timestamp.isoformat(),
            'metadata': self.metadata,
            'emotion_tag': self.emotion_tag.value if self.emotion_tag else None,
            'behavior_tag': self.behavior_tag.value if self.behavior_tag else None,
            'importance_score': self.importance_score,
            'topics': self.topics
        }
    
    @classmethod
    def from_dict(cls, data: Dict[str, Any]) -> 'EnhancedMessage':
        """–°–æ–∑–¥–∞–Ω–∏–µ –∏–∑ —Å–ª–æ–≤–∞—Ä—è"""
        return cls(
            role=data['role'],
            content=data['content'],
            timestamp=datetime.fromisoformat(data['timestamp']),
            metadata=data.get('metadata', {}),
            emotion_tag=EmotionTag(data['emotion_tag']) if data.get('emotion_tag') else None,
            behavior_tag=BehaviorTag(data['behavior_tag']) if data.get('behavior_tag') else None,
            importance_score=data.get('importance_score', 0.5),
            topics=data.get('topics', [])
        )


class SummaryEntry:
    """–ó–∞–ø–∏—Å—å —Å—É–º–º–∞—Ä–Ω–æ–π –ø–∞–º—è—Ç–∏"""
    
    def __init__(self, summary_text: str, last_updated: datetime, 
                 original_messages_count: int, importance_score: float = 0.5,
                 topics: List[str] = None, emotions: List[str] = None):
        self.summary_text = summary_text
        self.last_updated = last_updated
        self.original_messages_count = original_messages_count
        self.importance_score = importance_score
        self.topics = topics or []
        self.emotions = emotions or []
    
    def to_dict(self) -> Dict[str, Any]:
        """–ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –≤ —Å–ª–æ–≤–∞—Ä—å"""
        return {
            'summary_text': self.summary_text,
            'last_updated': self.last_updated.isoformat(),
            'original_messages_count': self.original_messages_count,
            'importance_score': self.importance_score,
            'topics': self.topics,
            'emotions': self.emotions
        }


class EnhancedBufferMemory(MemoryAdapter):
    """
    –£–ª—É—á—à–µ–Ω–Ω–∞—è –ø–∞–º—è—Ç—å —Å –±—É—Ñ–µ—Ä–æ–º, —Å—É–º–º–∞—Ä–∏–∑–∞—Ü–∏–µ–π –∏ —ç–º–æ—Ü–∏—è–º–∏
    –°–æ–≤–º–µ—Å—Ç–∏–º–∞ —Å —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–º –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–æ–º MemoryAdapter
    """
    
    def __init__(self, user_id: str, max_messages: int = None):
        super().__init__(user_id)
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é
        self.config = self._load_config()
        
        # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –±—É—Ñ–µ—Ä–∞
        self.max_messages = max_messages or self.config.get('buffer_limit', 15)
        self.summary_trigger = max(3, self.max_messages - 2)
        
        # –°–æ—Å—Ç–æ—è–Ω–∏–µ –ø–∞–º—è—Ç–∏
        self.messages: List[EnhancedMessage] = []
        self.summary_memory: List[SummaryEntry] = []
        self.last_activity: datetime = datetime.utcnow()
        self.total_messages = 0
        self.cursor_position: int = 0  # –ü–æ–∑–∏—Ü–∏—è –∫—É—Ä—Å–æ—Ä–∞ –≤ –¥–∏–∞–ª–æ–≥–µ
        self.session_id: str = f"session_{user_id}_{int(datetime.utcnow().timestamp())}"
        
        # –õ–æ–≥–≥–µ—Ä (–∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –°–ù–ê–ß–ê–õ–ê)
        self.logger = logging.getLogger(f"{__name__}.{user_id}")
        
        # LLM –¥–ª—è —Å—É–º–º–∞—Ä–∏–∑–∞—Ü–∏–∏
        self.llm = None
        if LANGCHAIN_AVAILABLE:
            self._initialize_llm()
        
        # –ú–µ—Ç—Ä–∏–∫–∏
        self.metrics = {
            'messages_added': 0,
            'summaries_created': 0,
            'emotions_detected': 0,
            'context_requests': 0
        }
        
        self.logger.info(f"EnhancedBufferMemory initialized for user {user_id}")
    
    def _load_config(self) -> Dict[str, Any]:
        """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é –±–µ–∑ —Ö–∞—Ä–¥–∫–æ–¥–∞"""
        if CONFIG_MANAGER_AVAILABLE:
            try:
                # –ò—Å–ø–æ–ª—å–∑—É–µ–º ProductionConfigManager –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ –ø—Ä–∞–≤–∏–ª—å–Ω–æ–π –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
                enhanced_config = get_config('enhanced_memory_config', self.user_id, {})
                system_config = get_config('system_defaults', self.user_id, {})
                
                return {
                    **enhanced_config,  # –ü–æ–ª–Ω–∞—è –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –¥–ª—è —ç–º–æ—Ü–∏–π, –≤–∞–∂–Ω–æ—Å—Ç–∏ –∏ —Ç–µ–º
                    **system_config.get('system', {}).get('limits', {}),
                    **system_config.get('system', {}).get('thresholds', {}).get('memory', {})
                }
            except Exception as e:
                self.logger.warning(f"Failed to load config from ProductionConfigManager: {e}")
        
        # Fallback –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è
        return {
            'buffer_limit': 15,
            'max_message_length': 4096,
            'importance_threshold': 0.6,
            'summarization_model': 'gpt-4o-mini',
            'summarization_temperature': 0.3,
            'auto_summarization': True,
            'emotion_detection': True
        }
    
    def _initialize_llm(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ—Ç LLM –¥–ª—è —Å—É–º–º–∞—Ä–∏–∑–∞—Ü–∏–∏"""
        try:
            import os
            api_key = os.getenv('OPENAI_API_KEY')
            if api_key:
                self.llm = ChatOpenAI(
                    model=self.config.get('summarization_model', 'gpt-4o-mini'),
                    temperature=self.config.get('summarization_temperature', 0.3),
                    max_tokens=self.config.get('max_tokens_summary', 500),
                    api_key=api_key
                )
                self.logger.info(f"LLM initialized for summarization")
            else:
                self.logger.warning("OpenAI API key not found")
        except Exception as e:
            self.logger.error(f"Failed to initialize LLM: {e}")
    
    def add_message(self, message: Message, context: MemoryContext) -> None:
        """–î–æ–±–∞–≤–ª—è–µ—Ç —Å–æ–æ–±—â–µ–Ω–∏–µ –≤ –±—É—Ñ–µ—Ä (—Å–æ–≤–º–µ—Å—Ç–∏–º–æ —Å –±–∞–∑–æ–≤—ã–º –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–æ–º)"""
        try:
            print(f"üìù [BUFFER-{context.user_id}] –î–æ–±–∞–≤–ª—è–µ–º —Å–æ–æ–±—â–µ–Ω–∏–µ: '{message.content[:50]}...'")
            
            # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ EnhancedMessage –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
            if isinstance(message, EnhancedMessage):
                enhanced_msg = message
                print(f"‚úÖ [BUFFER-{context.user_id}] –ò—Å–ø–æ–ª—å–∑—É–µ–º –≥–æ—Ç–æ–≤–æ–µ EnhancedMessage")
            else:
                print(f"üîÑ [BUFFER-{context.user_id}] –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ EnhancedMessage...")
                # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —ç–º–æ—Ü–∏—é –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏
                emotion_tag = self._detect_emotion(message.content) if self.config.get('emotion_detection', True) else None
                print(f"üòä [BUFFER-{context.user_id}] –≠–º–æ—Ü–∏—è: {emotion_tag}")
                
                # –í—ã—á–∏—Å–ª—è–µ–º –≤–∞–∂–Ω–æ—Å—Ç—å
                importance_score = self._calculate_importance(message.content, message.role)
                print(f"üìä [BUFFER-{context.user_id}] –í–∞–∂–Ω–æ—Å—Ç—å: {importance_score}")
                
                topics = self._extract_topics_single(message.content)
                
                enhanced_msg = EnhancedMessage(
                    role=message.role,
                    content=message.content,
                    timestamp=message.timestamp,
                    metadata=message.metadata,
                    emotion_tag=emotion_tag,
                    importance_score=importance_score,
                    topics=topics
                )
            
            # –î–æ–±–∞–≤–ª—è–µ–º –≤ –±—É—Ñ–µ—Ä
            self.messages.append(enhanced_msg)
            self.total_messages += 1
            self.cursor_position = len(self.messages) - 1  # –ö—É—Ä—Å–æ—Ä —É–∫–∞–∑—ã–≤–∞–µ—Ç –Ω–∞ –ø–æ—Å–ª–µ–¥–Ω–µ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ
            self.last_activity = datetime.utcnow()
            
            # –û–±–Ω–æ–≤–ª—è–µ–º –º–µ—Ç—Ä–∏–∫–∏
            self.metrics['messages_added'] += 1
            if enhanced_msg.emotion_tag and enhanced_msg.emotion_tag != EmotionTag.NEUTRAL:
                self.metrics['emotions_detected'] += 1
            if len(self.messages) > self.max_messages:
                self.messages = self.messages[-self.max_messages:]

            if (len(self.messages) >= self.summary_trigger and 
                self.config.get('auto_summarization', True) and 
                self.llm):
                try:
                    loop = asyncio.get_running_loop()
                    loop.create_task(self._trigger_summarization())
                except RuntimeError:
                    # –ù–µ—Ç –∑–∞–ø—É—â–µ–Ω–Ω–æ–≥–æ —Ü–∏–∫–ª–∞ ‚Äì –ø—Ä–æ–ø—É—Å–∫–∞–µ–º –∞–≤—Ç–æ-—Å—É–º–º–∞—Ä–∏–∑–∞—Ü–∏—é, —á—Ç–æ–±—ã –Ω–µ –ª–æ–º–∞—Ç—å –ø–æ—Ç–æ–∫
                    self.logger.warning("Auto-summarization skipped (no running event loop)")
            
            self.logger.debug(f"Message added: {message.role}, emotion: {enhanced_msg.emotion_tag}")
            
        except Exception as e:
            self.logger.error(f"Failed to add message: {e}")
    
    def _detect_emotion(self, text: str) -> Optional[EmotionTag]:

        try:

            emotion_markers = self.config.get('emotion_markers', {})
            
            text_lower = text.lower()
            

            for emotion_name, markers in emotion_markers.items():
                if any(marker in text_lower for marker in markers):
                    try:
                        return EmotionTag(emotion_name.lower())
                    except ValueError:
                        continue
            
            return EmotionTag.NEUTRAL
            
        except Exception as e:
            self.logger.warning(f"Emotion detection failed: {e}")
            return EmotionTag.NEUTRAL
    
    def _calculate_importance(self, text: str, role: str) -> float:
        try:

            importance_config = self.config.get('importance_calculation', {})
            
            # –ë–∞–∑–æ–≤–∞—è –≤–∞–∂–Ω–æ—Å—Ç—å –ø–æ —Ä–æ–ª–∏
            base_importance = importance_config.get('role_weights', {}).get(role, 0.5)
            
            text_lower = text.lower()
            
 
            importance_markers = importance_config.get('importance_markers', {})
            
            for category, data in importance_markers.items():
                markers = data.get('markers', [])
                weight = data.get('weight', 0.0)
                
                if any(marker in text_lower for marker in markers):
                    base_importance += weight
                    break 
            
            # –£—á–∏—Ç—ã–≤–∞–µ–º –¥–ª–∏–Ω—É —Å–æ–æ–±—â–µ–Ω–∏—è
            length_config = importance_config.get('length_weights', {})
            long_threshold = length_config.get('long_threshold', 200)
            short_threshold = length_config.get('short_threshold', 10)
            long_bonus = length_config.get('long_bonus', 0.1)
            short_penalty = length_config.get('short_penalty', -0.1)
            
            if len(text) > long_threshold:
                base_importance += long_bonus
            elif len(text) < short_threshold:
                base_importance += short_penalty
            
            return max(0.0, min(1.0, base_importance))
            
        except Exception:
            return 0.5
    
    async def _trigger_summarization(self):

        try:
            if not self.llm or len(self.messages) < 3:
                return
            
            messages_to_summarize = self.messages[:-2]
            if not messages_to_summarize:
                return
            
            # –°–æ–∑–¥–∞–µ–º –ø—Ä–æ–º—Ç –¥–ª—è —Å—É–º–º–∞—Ä–∏–∑–∞—Ü–∏–∏
            summary_prompt = self._build_summarization_prompt(messages_to_summarize)
            
            # –í—ã–∑—ã–≤–∞–µ–º LLM –¥–ª—è —Å—É–º–º–∞—Ä–∏–∑–∞—Ü–∏–∏
            summary_text = await self._generate_summary(summary_prompt)
            
            if summary_text:
                # –°–æ–∑–¥–∞–µ–º –∑–∞–ø–∏—Å—å —Å—É–º–º–∞—Ä–Ω–æ–π –ø–∞–º—è—Ç–∏
                summary_entry = SummaryEntry(
                    summary_text=summary_text,
                    last_updated=datetime.utcnow(),
                    original_messages_count=len(messages_to_summarize),
                    importance_score=self._calculate_summary_importance(messages_to_summarize),
                    topics=self._extract_topics(messages_to_summarize),
                    emotions=self._extract_emotions(messages_to_summarize)
                )
                

                self.summary_memory.append(summary_entry)
                

                if len(self.summary_memory) > 5:
                    self.summary_memory = self.summary_memory[-5:]
                

                self.messages = self.messages[-2:]
                
                self.metrics['summaries_created'] += 1
                self.logger.info(f"Summary created: {len(messages_to_summarize)} messages ‚Üí {len(summary_text)} chars")
            
        except Exception as e:
            self.logger.error(f"Summarization failed: {e}")
    
    def _build_summarization_prompt(self, messages: List[EnhancedMessage]) -> str:
        """–°—Ç—Ä–æ–∏—Ç –ø—Ä–æ–º—Ç –¥–ª—è —Å—É–º–º–∞—Ä–∏–∑–∞—Ü–∏–∏ –¥–∏–∞–ª–æ–≥–∞"""
        dialog_text = ""
        for msg in messages:
            role_prefix = "–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å" if msg.role == "user" else "–ê–≥–∞—Ç–∞"
            emotion_suffix = f" [—ç–º–æ—Ü–∏—è: {msg.emotion_tag.value}]" if msg.emotion_tag else ""
            dialog_text += f"{role_prefix}: {msg.content}{emotion_suffix}\n"
        
        template = """–°–æ–∑–¥–∞–π –∫—Ä–∞—Ç–∫–æ–µ —Ä–µ–∑—é–º–µ —Å–ª–µ–¥—É—é—â–µ–≥–æ –¥–∏–∞–ª–æ–≥–∞ –º–µ–∂–¥—É –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º –∏ AI-–∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–æ–º –ê–≥–∞—Ç–æ–π.

–î–∏–∞–ª–æ–≥ ({message_count} —Å–æ–æ–±—â–µ–Ω–∏–π):
{dialog}

–ò–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏ –¥–ª—è —Ä–µ–∑—é–º–µ:
1. –í—ã–¥–µ–ª–∏ –∫–ª—é—á–µ–≤—ã–µ —Ñ–∞–∫—Ç—ã –æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ (–∏–º—è, –∏–Ω—Ç–µ—Ä–µ—Å—ã, –ø–ª–∞–Ω—ã)
2. –û—Ç–º–µ—Ç—å –æ—Å–Ω–æ–≤–Ω—ã–µ —Ç–µ–º—ã —Ä–∞–∑–≥–æ–≤–æ—Ä–∞
3. –£–∫–∞–∂–∏ —ç–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–π —Ç–æ–Ω –¥–∏–∞–ª–æ–≥–∞
4. –°–æ—Ö—Ä–∞–Ω–∏ –≤–∞–∂–Ω—ã–µ –¥–µ—Ç–∞–ª–∏ –¥–ª—è –ø—Ä–æ–¥–æ–ª–∂–µ–Ω–∏—è —Ä–∞–∑–≥–æ–≤–æ—Ä–∞
5. –ú–∞–∫—Å–∏–º—É–º 3-4 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è

–†–µ–∑—é–º–µ:"""
        
        return template.format(
            dialog=dialog_text.strip(),
            message_count=len(messages)
        )
    
    async def _generate_summary(self, prompt: str) -> Optional[str]:
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç —Å—É–º–º–∞—Ä–Ω—ã–π —Ç–µ–∫—Å—Ç —Å –ø–æ–º–æ—â—å—é LLM"""
        try:
            messages = [SystemMessage(content=prompt)]
            response = await self.llm.ainvoke(messages)
            
            summary = response.content.strip()
            if len(summary) > 60:  
                return summary
            
            return None
            
        except Exception as e:
            self.logger.error(f"LLM summary generation failed: {e}")
            return None
    
    def _calculate_summary_importance(self, messages: List[EnhancedMessage]) -> float:

        if not messages:
            return 0.5
        
        # –°—Ä–µ–¥–Ω—è—è –≤–∞–∂–Ω–æ—Å—Ç—å —Å–æ–æ–±—â–µ–Ω–∏–π
        avg_importance = sum(msg.importance_score for msg in messages) / len(messages)
        
        # –ë–æ–Ω—É—Å –∑–∞ —ç–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å
        emotion_bonus = 0.1 if any(msg.emotion_tag and msg.emotion_tag != EmotionTag.NEUTRAL for msg in messages) else 0
        
        return min(1.0, avg_importance + emotion_bonus)
    
    def _extract_topics_single(self, text: str) -> List[str]:
        topics = set()
        

        topic_keywords = self.config.get('topic_keywords', {})
        
        text_lower = text.lower()
        for topic, keywords in topic_keywords.items():
            if any(keyword in text_lower for keyword in keywords):
                topics.add(topic)
        
        return list(topics)
    
    def _extract_topics(self, messages: List[EnhancedMessage]) -> List[str]:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç —Ç–µ–º—ã –∏–∑ —Å–æ–æ–±—â–µ–Ω–∏–π –±–µ–∑ —Ö–∞—Ä–¥–∫–æ–¥–∞"""
        topics = set()
        
        # –ü–æ–ª—É—á–∞–µ–º –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ –¥–ª—è —Ç–µ–º –∏–∑ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
        topic_keywords = self.config.get('topic_keywords', {})
        
        for msg in messages:
            text_lower = msg.content.lower()
            for topic, keywords in topic_keywords.items():
                if any(keyword in text_lower for keyword in keywords):
                    topics.add(topic)
        
        return list(topics)
    
    def _extract_emotions(self, messages: List[EnhancedMessage]) -> List[str]:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç —ç–º–æ—Ü–∏–∏ –∏–∑ —Å–æ–æ–±—â–µ–Ω–∏–π"""
        emotions = set()
        
        for msg in messages:
            if msg.emotion_tag and msg.emotion_tag != EmotionTag.NEUTRAL:
                emotions.add(msg.emotion_tag.value)
        
        return list(emotions)
    
    def get_conversation_context_tz(self) -> Dict[str, Any]:
        """
        –ü–æ–ª—É—á–∞–µ—Ç –∫–æ–Ω—Ç–µ–∫—Å—Ç –¥–∏–∞–ª–æ–≥–∞ –≤ —Ñ–æ—Ä–º–∞—Ç–µ –¢–ó –¥–ª—è compose_prompt
        
        Returns:
            Dict —Å–æ —Å—Ç—Ä—É–∫—Ç—É—Ä–æ–π –∏–∑ –¢–ó: user_id, session_id, buffer, summary_memory, config
        """
        try:
            # –§–æ—Ä–º–∏—Ä—É–µ–º –±—É—Ñ–µ—Ä –≤ —Ñ–æ—Ä–º–∞—Ç–µ –¢–ó
            buffer = []
            for i, msg in enumerate(self.messages):
                msg_dict = {
                    "role": msg.role,
                    "text": msg.content,
                    "timestamp": msg.timestamp.isoformat(),
                    "cursor_active": i == self.cursor_position,  # –ü–æ–º–µ—á–∞–µ–º –∞–∫—Ç–∏–≤–Ω—É—é –ø–æ–∑–∏—Ü–∏—é –∫—É—Ä—Å–æ—Ä–∞
                    "importance_score": msg.importance_score,  # –í–∞–∂–Ω–æ—Å—Ç—å —Å–æ–æ–±—â–µ–Ω–∏—è
                    "topics": msg.topics  # –û–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω—ã–µ —Ç–µ–º—ã
                }
                
                # –î–æ–±–∞–≤–ª—è–µ–º —Ç–µ–≥–∏ –µ—Å–ª–∏ –µ—Å—Ç—å
                if msg.emotion_tag and msg.emotion_tag != EmotionTag.NEUTRAL:
                    msg_dict["emotion_tag"] = msg.emotion_tag.value
                    
                if msg.behavior_tag:
                    msg_dict["behavior_tag"] = msg.behavior_tag.value
                    
                buffer.append(msg_dict)
            
            # –§–æ—Ä–º–∏—Ä—É–µ–º summary_memory –≤ —Ñ–æ—Ä–º–∞—Ç–µ –¢–ó
            summary_memory = []
            for summary in self.summary_memory:
                summary_memory.append({
                    "summary_text": summary.summary_text,
                    "last_updated": summary.last_updated.isoformat(),
                    "original_messages_count": summary.original_messages_count,
                    "topics": summary.topics,
                    "emotions": summary.emotions
                })
            
            # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –≤ —Ñ–æ—Ä–º–∞—Ç–µ –¢–ó
            return {
                "user_id": self.user_id,
                "session_id": self.session_id,
                "buffer": buffer,
                "summary_memory": summary_memory,
                "config": {
                    "buffer_limit": self.max_messages,
                    "summary_trigger": self.summary_trigger,
                    "cursor_position": self.cursor_position
                },
                "stats": {
                    "total_messages": self.total_messages,
                    "current_buffer_size": len(self.messages),
                    "summary_entries": len(self.summary_memory)
                }
            }
            
        except Exception as e:
            self.logger.error(f"Failed to generate conversation context: {e}")
            return {
                "user_id": self.user_id,
                "session_id": self.session_id,
                "buffer": [],
                "summary_memory": [],
                "config": {"buffer_limit": self.max_messages, "cursor_position": 0},
                "error": str(e)
            }

    def get_context(self, context: MemoryContext) -> str:
        """–ü–æ–ª—É—á–∞–µ—Ç –∫–æ–Ω—Ç–µ–∫—Å—Ç –¥–ª—è –ø—Ä–æ–º–ø—Ç–∞ (—Å–æ–≤–º–µ—Å—Ç–∏–º–æ —Å –±–∞–∑–æ–≤—ã–º –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–æ–º)"""
        try:
            self.metrics['context_requests'] += 1
            
            context_parts = []
            
            # –î–æ–±–∞–≤–ª—è–µ–º —Å—É–º–º–∞—Ä–Ω—É—é –ø–∞–º—è—Ç—å
            if self.summary_memory:
                context_parts.append("–ü—Ä–µ–¥—ã–¥—É—â–∏–µ —Ä–∞–∑–≥–æ–≤–æ—Ä—ã:")
                for summary in self.summary_memory[-3:]:  # –ü–æ—Å–ª–µ–¥–Ω–∏–µ 3 —Ä–µ–∑—é–º–µ
                    topics_str = f" (—Ç–µ–º—ã: {', '.join(summary.topics)})" if summary.topics else ""
                    emotions_str = f" [—ç–º–æ—Ü–∏–∏: {', '.join(summary.emotions)}]" if summary.emotions else ""
                    context_parts.append(f"‚Ä¢ {summary.summary_text}{topics_str}{emotions_str}")
            
            # –î–æ–±–∞–≤–ª—è–µ–º –≤—Ä–µ–º–µ–Ω–Ω–æ–π –∫–æ–Ω—Ç–µ–∫—Å—Ç
            time_gap = datetime.utcnow() - self.last_activity
            if time_gap > timedelta(hours=6):
                context_parts.append(f"–ü—Ä–æ—à–ª–æ {self._format_time_gap(time_gap)} —Å –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏—è.")
            
            # –ò–∑–≤–ª–µ–∫–∞–µ–º –∫–ª—é—á–µ–≤—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é (–∫–∞–∫ –≤ –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–π BufferMemory)
            key_info = self._extract_key_information()
            if key_info:
                context_parts.append(f"–ö–ª—é—á–µ–≤–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è: {key_info}")
            
            # –î–æ–±–∞–≤–ª—è–µ–º –Ω–µ–¥–∞–≤–Ω–∏–π —Ä–∞–∑–≥–æ–≤–æ—Ä
            if self.messages:
                context_parts.append("–ù–µ–¥–∞–≤–Ω–∏–π —Ä–∞–∑–≥–æ–≤–æ—Ä:")
                for msg in self.messages[-5:]:  # –ü–æ—Å–ª–µ–¥–Ω–∏–µ 5 —Å–æ–æ–±—â–µ–Ω–∏–π
                    role = "–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å" if msg.role == "user" else "–¢—ã"
                    emotion_suffix = f" [{msg.emotion_tag.value}]" if msg.emotion_tag and msg.emotion_tag != EmotionTag.NEUTRAL else ""
                    context_parts.append(f"{role}: {msg.content}{emotion_suffix}")
            else:
                context_parts.append("–≠—Ç–æ –Ω–∞—á–∞–ª–æ –≤–∞—à–µ–≥–æ —Ä–∞–∑–≥–æ–≤–æ—Ä–∞.")
            
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –¥–æ–º–∏–Ω–∏—Ä—É—é—â—É—é —ç–º–æ—Ü–∏—é –∏ –ø–æ–≤–µ–¥–µ–Ω–∏–µ
            dominant_emotion = self._get_dominant_emotion()
            current_behavior = self._determine_current_behavior(dominant_emotion)
            
            if dominant_emotion and dominant_emotion != EmotionTag.NEUTRAL:
                context_parts.append(f"–¢–µ–∫—É—â–∞—è —ç–º–æ—Ü–∏—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è: {dominant_emotion.value}")
            
            if current_behavior:
                context_parts.append(f"–†–µ–∫–æ–º–µ–Ω–¥—É–µ–º–æ–µ –ø–æ–≤–µ–¥–µ–Ω–∏–µ: {current_behavior.value}")
            
            return "\n".join(context_parts)
            
        except Exception as e:
            self.logger.error(f"Failed to generate context: {e}")
            return "–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞."
    
    def _get_dominant_emotion(self) -> Optional[EmotionTag]:
        """–û–ø—Ä–µ–¥–µ–ª—è–µ—Ç –¥–æ–º–∏–Ω–∏—Ä—É—é—â—É—é —ç–º–æ—Ü–∏—é –≤ —Ç–µ–∫—É—â–µ–º –±—É—Ñ–µ—Ä–µ"""
        if not self.messages:
            return None
        
        emotion_counts = {}
        recent_weight = 2.0  # –ë–æ–ª—å—à–∏–π –≤–µ—Å –¥–ª—è –Ω–µ–¥–∞–≤–Ω–∏—Ö —Å–æ–æ–±—â–µ–Ω–∏–π
        
        for i, msg in enumerate(self.messages):
            if msg.emotion_tag and msg.emotion_tag != EmotionTag.NEUTRAL:
                weight = recent_weight if i >= len(self.messages) - 3 else 1.0
                emotion_counts[msg.emotion_tag] = emotion_counts.get(msg.emotion_tag, 0) + weight
        
        if emotion_counts:
            return max(emotion_counts.keys(), key=lambda e: emotion_counts[e])
        
        return EmotionTag.NEUTRAL
    
    def _determine_current_behavior(self, dominant_emotion: Optional[EmotionTag]) -> Optional[BehaviorTag]:
        """–û–ø—Ä–µ–¥–µ–ª—è–µ—Ç —Ä–µ–∫–æ–º–µ–Ω–¥—É–µ–º–æ–µ –ø–æ–≤–µ–¥–µ–Ω–∏–µ –Ω–∞ –æ—Å–Ω–æ–≤–µ —ç–º–æ—Ü–∏–π"""
        if not dominant_emotion:
            return BehaviorTag.FRIENDLY
        
        behavior_mapping = {
            EmotionTag.SAD: BehaviorTag.SUPPORTIVE,
            EmotionTag.WORRIED: BehaviorTag.SUPPORTIVE,
            EmotionTag.HAPPY: BehaviorTag.PLAYFUL,
            EmotionTag.EXCITED: BehaviorTag.PLAYFUL,
            EmotionTag.FRUSTRATED: BehaviorTag.CARE,
            EmotionTag.CONFUSED: BehaviorTag.CARE,
            EmotionTag.GRATEFUL: BehaviorTag.FRIENDLY,
            EmotionTag.NEUTRAL: BehaviorTag.FRIENDLY
        }
        
        return behavior_mapping.get(dominant_emotion, BehaviorTag.FRIENDLY)
    
    def _extract_key_information(self) -> str:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –∫–ª—é—á–µ–≤—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é (—Å–æ–≤–º–µ—Å—Ç–∏–º–æ —Å –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–π BufferMemory)"""
        user_messages = [msg for msg in self.messages if msg.role == "user"]
        if not user_messages:
            return ""
        
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º –ª–æ–≥–∏–∫—É –∏–∑ –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–π BufferMemory
        all_text = " ".join([msg.content for msg in user_messages])
        text_lower = all_text.lower()
        
        key_info = []
        
        # –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –∏–º–µ–Ω–∏
        # –°–Ω–∞—á–∞–ª–∞ —è–≤–Ω—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã –≤—Ä–æ–¥–µ "–ú–µ–Ω—è –∑–æ–≤—É—Ç –ú–∞—Ä–∏—è" / "–ú–æ—ë –∏–º—è –ú–∞—Ä–∏—è" / "–Ø –ú–∞—Ä–∏—è"
        import re
        # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –ø—Ä–æ–±–µ–ª—ã
        normalized = re.sub(r'\s+', ' ', all_text.strip())
        # –Ø–≤–Ω—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã –∏–º–µ–Ω–∏
        name_match = re.search(r'(?:–º–µ–Ω—è\s+–∑–æ–≤—É—Ç|–º–æ[–µ—ë]\s+–∏–º—è)\s+([A-–Ø–Å][–∞-—è—ë]+)\b', normalized, flags=re.IGNORECASE)
        if name_match:
            name = name_match.group(1)
            key_info.append(f"–ò–º—è: {name}")
        else:
            # –î–æ–ø. –ø–∞—Ç—Ç–µ—Ä–Ω: "—è –ú–∞—Ä–∏—è" –≤ –Ω–∞—á–∞–ª–µ –∏–ª–∏ –ø–æ—Å–ª–µ —Ç–æ—á–∫–∏/–Ω–∞—á–∞–ª–∞ —Å—Ç—Ä–æ–∫–∏
            name_match2 = re.search(r'(?:^|[\.!?]\s*)—è\s+([A-–Ø–Å][–∞-—è—ë]+)\b', normalized)
            if name_match2:
                name = name_match2.group(1)
                key_info.append(f"–ò–º—è: {name}")
            else:
                # –ü–æ–∏—Å–∫ —Å–ª–æ–≤–∞ —Å –∑–∞–≥–ª–∞–≤–Ω–æ–π –±—É–∫–≤—ã –ø–æ—Å–ª–µ –∫–ª—é—á–µ–≤—ã—Ö —Ç—Ä–∏–≥–≥–µ—Ä–æ–≤, –≤–∫–ª—é—á–∞—è "–∑–æ–≤—É—Ç"
                words = normalized.split()
                for i, word in enumerate(words):
                    lw = word.lower().strip(',.!?')
                    if lw in ["—è", "–º–µ–Ω—è", "–º–Ω–µ", "–∑–æ–≤—É—Ç"] and i + 1 < len(words):
                        next_word = words[i + 1].strip(',.!?')
                        if (len(next_word) > 2 and next_word[0].isupper() and next_word.isalpha()
                            and next_word not in ["–ú–µ–Ω—è", "–ú–Ω–µ", "–Ø", "–ó–æ–≤—É—Ç"]):
                            key_info.append(f"–ò–º—è: {next_word}")
                            break
            for i, word in enumerate(words):
                if word.lower() in ["—è", "–º–µ–Ω—è", "–º–Ω–µ"] and i + 1 < len(words):
                    next_word = words[i + 1].replace(',', '').replace('.', '').replace('!', '')
                    if len(next_word) > 2 and next_word[0].isupper() and next_word.isalpha():
                        key_info.append(f"–ò–º—è: {next_word}")
                        break
        
        # –ò–°–ü–†–ê–í–õ–ï–ù–û: –£–±–∏—Ä–∞–µ–º —Ö–∞—Ä–¥–∫–æ–¥ –≤–æ–∑—Ä–∞—Å—Ç–Ω—ã—Ö –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤
        # –ò—â–µ–º —á–∏—Å–ª–∞ –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ —Å –ø–æ–º–æ—â—å—é regex
        age_match = re.search(r'\b(\d{1,3})\s*(?:–ª–µ—Ç|–≥–æ–¥–∞|–≥–æ–¥)\b', text_lower)
        if age_match:
            age = int(age_match.group(1))
            if 1 <= age <= 120:
                key_info.append(f"–í–æ–∑—Ä–∞—Å—Ç: {age} –ª–µ—Ç")
        
        # –ò–°–ü–†–ê–í–õ–ï–ù–û: –£–±–∏—Ä–∞–µ–º —Ö–∞—Ä–¥–∫–æ–¥ –ø—Ä–æ—Ñ–µ—Å—Å–∏–π
        # –ò—â–µ–º –ø—Ä–æ—Ñ–µ—Å—Å–∏—é —á–µ—Ä–µ–∑ regex –ø–∞—Ç—Ç–µ—Ä–Ω—ã
        def normalize_profession(word: str) -> str:
            # –ü—Ä–æ—Å—Ç–µ–π—à–∞—è –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –ø–∞–¥–µ–∂–µ–π –¥–ª—è –æ–±—â–∏—Ö –ø—Ä–æ—Ñ–µ—Å—Å–∏–π
            if word.endswith('–∏—Ç–µ–ª–µ–º'):
                return word[:-6] + '–∏—Ç–µ–ª—å'
            if word.endswith('–æ–º') or word.endswith('–µ–º'):
                # –≥—Ä—É–±–æ–µ —É—Å–µ—á–µ–Ω–∏–µ –ø–∞–¥–µ–∂–∞
                return word[:-2]
            return word

        work_match = re.search(r'—Ä–∞–±–æ—Ç–∞—é\s+(\w+)', text_lower)
        if work_match:
            profession = normalize_profession(work_match.group(1))
            if len(profession) > 2:
                key_info.append(f"–ü—Ä–æ—Ñ–µ—Å—Å–∏—è: {profession}")
        else:
            # –ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–π –ø–æ–∏—Å–∫ —á–µ—Ä–µ–∑ "—è <–ø—Ä–æ—Ñ–µ—Å—Å–∏—è>"
            profession_match = re.search(r'—è\s+(\w+(?:–∏—Å—Ç|–µ—Ä|–æ—Ä|–∏–∫|–∏—Ç–µ–ª—å))\b', text_lower)
            if profession_match:
                profession = normalize_profession(profession_match.group(1))
                key_info.append(f"–ü—Ä–æ—Ñ–µ—Å—Å–∏—è: {profession}")
        
        return "; ".join(key_info) if key_info else ""
    
    def search_memory(self, query: str, limit: int = 5) -> List[Dict[str, Any]]:
        """–ü–æ–∏—Å–∫ –≤ –ø–∞–º—è—Ç–∏ (—Å–æ–≤–º–µ—Å—Ç–∏–º–æ —Å –±–∞–∑–æ–≤—ã–º –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–æ–º)"""
        results = []
        query_lower = query.lower()
        
        # –ü–æ–∏—Å–∫ –≤ —Ç–µ–∫—É—â–∏—Ö —Å–æ–æ–±—â–µ–Ω–∏—è—Ö
        for msg in reversed(self.messages):
            if query_lower in msg.content.lower():
                results.append({
                    "content": msg.content,
                    "role": msg.role,
                    "timestamp": msg.timestamp,
                    "emotion_tag": msg.emotion_tag.value if msg.emotion_tag else None,
                    "importance_score": msg.importance_score,
                    "relevance": 1.0
                })
                if len(results) >= limit:
                    break
        
        # –ü–æ–∏—Å–∫ –≤ —Å—É–º–º–∞—Ä–Ω–æ–π –ø–∞–º—è—Ç–∏
        for summary in reversed(self.summary_memory):
            if query_lower in summary.summary_text.lower():
                results.append({
                    "content": summary.summary_text,
                    "role": "summary",
                    "timestamp": summary.last_updated,
                    "topics": summary.topics,
                    "emotions": summary.emotions,
                    "importance_score": summary.importance_score,
                    "relevance": 0.8
                })
                if len(results) >= limit:
                    break
        
        return results
    
    def summarize_conversation(self, messages: List[Message]) -> str:
        """–°—É–º–º–∞—Ä–∏–∑–∞—Ü–∏—è –¥–∏–∞–ª–æ–≥–∞ (—Å–æ–≤–º–µ—Å—Ç–∏–º–æ —Å –±–∞–∑–æ–≤—ã–º –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–æ–º)"""
        if not messages:
            return "–ù–µ—Ç —Å–æ–æ–±—â–µ–Ω–∏–π –¥–ª—è –æ–±–æ–±—â–µ–Ω–∏—è."
        
        # –ï—Å–ª–∏ –¥–æ—Å—Ç—É–ø–µ–Ω LLM, –∏—Å–ø–æ–ª—å–∑—É–µ–º –µ–≥–æ
        if self.llm:
            try:
                enhanced_messages = []
                for msg in messages:
                    if isinstance(msg, EnhancedMessage):
                        enhanced_messages.append(msg)
                    else:
                        enhanced_messages.append(EnhancedMessage(
                            role=msg.role,
                            content=msg.content,
                            timestamp=msg.timestamp,
                            metadata=msg.metadata
                        ))
                
                prompt = self._build_summarization_prompt(enhanced_messages)
                # –°–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–π –≤—ã–∑–æ–≤ –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏
                loop = asyncio.new_event_loop()
                asyncio.set_event_loop(loop)
                summary = loop.run_until_complete(self._generate_summary(prompt))
                loop.close()
                
                # –ì–∞—Ä–∞–Ω—Ç–∏—Ä—É–µ–º –Ω–∞–ª–∏—á–∏–µ —Ñ—Ä–∞–∑—ã —Å –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ–º —Å–æ–æ–±—â–µ–Ω–∏–π –∏ —Ä–∞–∑–±–∏–µ–Ω–∏–µ –ø–æ —Ä–æ–ª—è–º –¥–ª—è —Ç–µ—Å—Ç–∞
                if summary:
                    user_messages = [m for m in messages if m.role == "user"]
                    assistant_messages = [m for m in messages if m.role == "assistant"]
                    prefix = (
                        f"–†–∞–∑–≥–æ–≤–æ—Ä –∏–∑ {len(messages)} —Å–æ–æ–±—â–µ–Ω–∏–π. "
                        f"–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –Ω–∞–ø–∏—Å–∞–ª {len(user_messages)} —Å–æ–æ–±—â–µ–Ω–∏–π, "
                        f"–∞—Å—Å–∏—Å—Ç–µ–Ω—Ç –æ—Ç–≤–µ—Ç–∏–ª {len(assistant_messages)} —Ä–∞–∑. "
                    )
                    return prefix + summary
                return self._simple_summarize(messages)
                
            except Exception as e:
                self.logger.error(f"LLM summarization failed: {e}")
                return self._simple_summarize(messages)
        else:
            return self._simple_summarize(messages)
    
    def _simple_summarize(self, messages: List[Message]) -> str:
        """–ü—Ä–æ—Å—Ç–∞—è —Å—É–º–º–∞—Ä–∏–∑–∞—Ü–∏—è –±–µ–∑ LLM"""
        user_messages = [m for m in messages if m.role == "user"]
        assistant_messages = [m for m in messages if m.role == "assistant"]
        
        summary = f"–†–∞–∑–≥–æ–≤–æ—Ä –∏–∑ {len(messages)} —Å–æ–æ–±—â–µ–Ω–∏–π. "
        summary += f"–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –Ω–∞–ø–∏—Å–∞–ª {len(user_messages)} —Å–æ–æ–±—â–µ–Ω–∏–π, "
        summary += f"–∞—Å—Å–∏—Å—Ç–µ–Ω—Ç –æ—Ç–≤–µ—Ç–∏–ª {len(assistant_messages)} —Ä–∞–∑."
        
        return summary
    
    def clear_memory(self) -> None:
        """–û—á–∏—Å—Ç–∫–∞ –ø–∞–º—è—Ç–∏ (—Å–æ–≤–º–µ—Å—Ç–∏–º–æ —Å –±–∞–∑–æ–≤—ã–º –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–æ–º)"""
        self.messages.clear()
        self.summary_memory.clear()
        self.last_activity = datetime.utcnow()
        self.total_messages = 0
        self.logger.info(f"Memory cleared for user {self.user_id}")
    
    def _format_time_gap(self, gap: timedelta) -> str:
        """–§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –≤—Ä–µ–º–µ–Ω–Ω–æ–≥–æ –ø—Ä–æ–º–µ–∂—É—Ç–∫–∞"""
        if gap.days > 0:
            return f"{gap.days} –¥–Ω."
        elif gap.seconds > 3600:
            hours = gap.seconds // 3600
            return f"{hours} —á."
        else:
            minutes = gap.seconds // 60
            return f"{minutes} –º–∏–Ω."
    
    def get_metrics(self) -> Dict[str, Any]:
        """–ü–æ–ª—É—á–∞–µ—Ç –º–µ—Ç—Ä–∏–∫–∏ —Ä–∞–±–æ—Ç—ã –ø–∞–º—è—Ç–∏"""
        return {
            **self.metrics,
            'current_buffer_size': len(self.messages),
            'summary_entries': len(self.summary_memory),
            'avg_importance': sum(msg.importance_score for msg in self.messages) / max(len(self.messages), 1),
            'dominant_emotion': self._get_dominant_emotion().value if self._get_dominant_emotion() else None,
            'config': {
                'max_messages': self.max_messages,
                'auto_summarization': self.config.get('auto_summarization', True),
                'emotion_detection': self.config.get('emotion_detection', True)
            }
        }
    
    def export_data(self) -> Dict[str, Any]:
        """–≠–∫—Å–ø–æ—Ä—Ç–∏—Ä—É–µ—Ç –¥–∞–Ω–Ω—ã–µ –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è"""
        return {
            'user_id': self.user_id,
            'messages': [msg.to_dict() for msg in self.messages],
            'summary_memory': [summary.to_dict() for summary in self.summary_memory],
            'last_activity': self.last_activity.isoformat(),
            'total_messages': self.total_messages,
            'metrics': self.metrics,
            'exported_at': datetime.utcnow().isoformat()
        }
    
    def import_data(self, data: Dict[str, Any]) -> bool:
        """–ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ—Ç –¥–∞–Ω–Ω—ã–µ"""
        try:
            # –í–æ—Å—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º —Å–æ–æ–±—â–µ–Ω–∏—è
            self.messages = [
                EnhancedMessage.from_dict(msg_data) 
                for msg_data in data.get('messages', [])
            ]
            
            # –í–æ—Å—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º —Å—É–º–º–∞—Ä–Ω—É—é –ø–∞–º—è—Ç—å
            self.summary_memory = []
            for summary_data in data.get('summary_memory', []):
                summary = SummaryEntry(
                    summary_text=summary_data['summary_text'],
                    last_updated=datetime.fromisoformat(summary_data['last_updated']),
                    original_messages_count=summary_data.get('original_messages_count', 0),
                    importance_score=summary_data.get('importance_score', 0.5),
                    topics=summary_data.get('topics', []),
                    emotions=summary_data.get('emotions', [])
                )
                self.summary_memory.append(summary)
            
            # –í–æ—Å—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
            if 'last_activity' in data:
                self.last_activity = datetime.fromisoformat(data['last_activity'])
            
            self.total_messages = data.get('total_messages', len(self.messages))
            
            if 'metrics' in data:
                self.metrics.update(data['metrics'])
            
            self.logger.info(f"Data imported: {len(self.messages)} messages, {len(self.summary_memory)} summaries")
            return True
            
        except Exception as e:
            self.logger.error(f"Failed to import data: {e}")
            return False