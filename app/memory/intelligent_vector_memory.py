"""
–ò–Ω—Ç–µ–ª–ª–µ–∫—Ç—É–∞–ª—å–Ω–∞—è –≤–µ–∫—Ç–æ—Ä–Ω–∞—è –ø–∞–º—è—Ç—å —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π LangChain
–ò–Ω—Ç–µ–≥—Ä–∏—Ä—É–µ—Ç—Å—è —Å ChromaDB –∏ –æ–±–µ—Å–ø–µ—á–∏–≤–∞–µ—Ç —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–π –ø–æ–∏—Å–∫
–ü–æ–ª–Ω–æ—Å—Ç—å—é –±–µ–∑ —Ö–∞—Ä–¥–∫–æ–¥–∞ - –≤—Å–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –∏–∑ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
"""
import logging
import asyncio
from typing import List, Dict, Any, Optional, Tuple
from datetime import datetime, timedelta
from dataclasses import dataclass

# LangChain –∏–º–ø–æ—Ä—Ç—ã —Å –ø—Ä–æ–≤–µ—Ä–∫–æ–π –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç–∏
try:
    from langchain_openai import OpenAIEmbeddings
    from langchain_community.vectorstores import Chroma
    from langchain_core.documents import Document
    from langchain_core.embeddings import Embeddings
    LANGCHAIN_AVAILABLE = True
except ImportError:
    LANGCHAIN_AVAILABLE = False

# ChromaDB –∏–º–ø–æ—Ä—Ç—ã —Å –ø—Ä–æ–≤–µ—Ä–∫–æ–π –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç–∏
try:
    import chromadb
    from chromadb.config import Settings
    CHROMADB_AVAILABLE = True
except ImportError:
    CHROMADB_AVAILABLE = False

# –ò–º–ø–æ—Ä—Ç—ã –ø—Ä–æ–µ–∫—Ç–∞
from .base import MemoryAdapter, Message, MemoryContext
try:
    from ..config.production_config_manager import get_config
    CONFIG_MANAGER_AVAILABLE = True
except ImportError:
    CONFIG_MANAGER_AVAILABLE = False


@dataclass
class MemoryDocument:
    """–î–æ–∫—É–º–µ–Ω—Ç –¥–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è –≤ –≤–µ–∫—Ç–æ—Ä–Ω–æ–π –ø–∞–º—è—Ç–∏"""
    content: str
    metadata: Dict[str, Any]
    embedding: Optional[List[float]] = None
    created_at: datetime = None
    importance_score: float = 0.5
    
    def __post_init__(self):
        if self.created_at is None:
            self.created_at = datetime.utcnow()


class IntelligentVectorMemory:
    """
    –ò–Ω—Ç–µ–ª–ª–µ–∫—Ç—É–∞–ª—å–Ω–∞—è –≤–µ–∫—Ç–æ—Ä–Ω–∞—è –ø–∞–º—è—Ç—å —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–æ–≥–æ –ø–æ–∏—Å–∫–∞
    –ò—Å–ø–æ–ª—å–∑—É–µ—Ç ChromaDB + OpenAI Embeddings –¥–ª—è –¥–æ–ª–≥–æ—Å—Ä–æ—á–Ω–æ–≥–æ —Ö—Ä–∞–Ω–µ–Ω–∏—è
    """
    
    def __init__(self, user_id: str, collection_name: Optional[str] = None):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç—É–∞–ª—å–Ω–æ–π –≤–µ–∫—Ç–æ—Ä–Ω–æ–π –ø–∞–º—è—Ç–∏
        
        Args:
            user_id: –ò–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ç–æ—Ä –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
            collection_name: –ò–º—è –∫–æ–ª–ª–µ–∫—Ü–∏–∏ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é user_id)
        """
        self.user_id = user_id
        self.collection_name = collection_name or f"user_{user_id}"
        self.logger = logging.getLogger(f"{__name__}.{user_id}")
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é
        self.config = self._load_config()
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã
        self.embeddings = None
        self.vectorstore = None
        self.chroma_client = None
        
        print(f"üöÄ [VECTOR-{user_id}] –°–æ–∑–¥–∞–µ–º IntelligentVectorMemory...")
        if LANGCHAIN_AVAILABLE and CHROMADB_AVAILABLE:
            print(f"‚úÖ [VECTOR-{user_id}] LangChain –∏ ChromaDB –¥–æ—Å—Ç—É–ø–Ω—ã, –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º...")
            self._initialize_components()
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏
            if self.vectorstore is None:
                self.logger.error(f"‚ùå [VECTOR-{user_id}] –ö–†–ò–¢–ò–ß–ï–°–ö–ê–Ø –û–®–ò–ë–ö–ê: vectorstore –æ—Å—Ç–∞–ª—Å—è None –ø–æ—Å–ª–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏!")
                
                try:
                    self.logger.warning(f"üîÑ [VECTOR-{user_id}] –ü—ã—Ç–∞–µ–º—Å—è fallback –Ω–∞ EphemeralClient...")
                    import chromadb
                    from langchain_community.vectorstores import Chroma
                    from langchain_openai import OpenAIEmbeddings
                    import os
                    
                    openai_key = os.getenv('OPENAI_API_KEY')
                    if openai_key:
                        self.embeddings = OpenAIEmbeddings(model='text-embedding-3-small', openai_api_key=openai_key)
                        self.chroma_client = chromadb.EphemeralClient()
                        self.vectorstore = Chroma(
                            client=self.chroma_client,
                            collection_name=self.collection_name,
                            embedding_function=self.embeddings
                        )
                        self.logger.info(f"‚úÖ [VECTOR-{user_id}] Fallback –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —É—Å–ø–µ—à–Ω–∞ (EphemeralClient)")
                    else:
                        self.logger.error(f"‚ùå [VECTOR-{user_id}] –ù–µ—Ç OpenAI –∫–ª—é—á–∞ –¥–ª—è fallback")
                except Exception as fallback_error:
                    self.logger.error(f"‚ùå [VECTOR-{user_id}] Fallback —Ç–æ–∂–µ –Ω–µ —Å—Ä–∞–±–æ—Ç–∞–ª: {fallback_error}")
            else:
                self.logger.info(f"‚úÖ [VECTOR-{user_id}] vectorstore —É—Å–ø–µ—à–Ω–æ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")
        else:
            print(f"‚ùå [VECTOR-{user_id}] LangChain –∏–ª–∏ ChromaDB –Ω–µ–¥–æ—Å—Ç—É–ø–Ω—ã!")
            self.logger.warning("LangChain or ChromaDB not available - using fallback mode")
        
        self.logger.info(f"IntelligentVectorMemory initialized for user {user_id}")
    
    def _load_config(self) -> Dict[str, Any]:
        """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é –±–µ–∑ —Ö–∞—Ä–¥–∫–æ–¥–∞"""
        if CONFIG_MANAGER_AVAILABLE:
            try:
                # –ó–∞–≥—Ä—É–∂–∞–µ–º –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é –≤–µ–∫—Ç–æ—Ä–Ω–æ–π –ø–∞–º—è—Ç–∏
                vector_config = get_config('vector_memory_config', self.user_id, {})
                enhanced_config = get_config('enhanced_memory_config', self.user_id, {})
                
                return {
                    **vector_config,
                    'llm': enhanced_config.get('llm', {}),
                    'features': enhanced_config.get('features', {})
                }
            except Exception as e:
                self.logger.warning(f"Failed to load config: {e}")
        
        # Fallback –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è
        return {
            'embedding_model': 'text-embedding-ada-002',
            'collection_settings': {
                'distance_function': 'cosine',
                'max_documents': 10000
            },
            'search_settings': {
                'similarity_threshold': 0.7,
                'max_results': 5,
                'include_metadata': True
            },
            'persistence': {
                'enabled': True,
                'path': './data/chroma_db'
            },
            'features': {
                'auto_cleanup': True,
                'importance_filtering': True,
                'temporal_decay': True
            }
        }
    
    def _initialize_components(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ—Ç LangChain –∏ ChromaDB –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã"""
        self.logger.error(f"üöÄ [VECTOR-{self.user_id}] –ú–ï–¢–û–î _initialize_components –í–´–ó–í–ê–ù!")
        try:
            import os
            
            print(f"üîß [VECTOR-{self.user_id}] –ù–∞—á–∏–Ω–∞–µ–º –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—é –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤...")
            self.logger.warning(f"üîß [VECTOR-{self.user_id}] –ù–∞—á–∏–Ω–∞–µ–º –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—é –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤...")
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º OpenAI API –∫–ª—é—á
            openai_key = os.getenv('OPENAI_API_KEY')
            if not openai_key:
                print(f"‚ùå [VECTOR-{self.user_id}] OPENAI_API_KEY –Ω–µ –Ω–∞–π–¥–µ–Ω!")
                raise ValueError("OPENAI_API_KEY not found in environment variables")
            
            self.logger.warning(f"‚úÖ [VECTOR-{self.user_id}] OpenAI –∫–ª—é—á –Ω–∞–π–¥–µ–Ω")
            
            # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º embeddings
            embedding_model = self.config.get('embedding_model', 'text-embedding-3-small')
            print(f"üîß [VECTOR-{self.user_id}] –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º embeddings: {embedding_model}")
            self.embeddings = OpenAIEmbeddings(model=embedding_model, openai_api_key=openai_key)
            self.logger.debug(f"Embeddings initialized with model: {embedding_model}")
            print(f"‚úÖ [VECTOR-{self.user_id}] Embeddings –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω—ã")
            
            # –ù–∞—Å—Ç—Ä–æ–π–∫–∏ ChromaDB - —É–ø—Ä–æ—â–µ–Ω–Ω–∞—è –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è
            persistence_config = self.config.get('persistence', {})
            print(f"üîß [VECTOR-{self.user_id}] –ù–∞—Å—Ç—Ä–æ–π–∫–∏ persistence: {persistence_config}")
            
            if persistence_config.get('enabled', True):
                persist_directory = persistence_config.get('path', './data/chroma_db')
                # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤ –∞–±—Å–æ–ª—é—Ç–Ω—ã–π –ø—É—Ç—å
                persist_directory = os.path.abspath(persist_directory)
                self.logger.warning(f"üìÅ [VECTOR-{self.user_id}] –°–æ–∑–¥–∞–µ–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é: {persist_directory}")
                
                # –°–æ–∑–¥–∞–µ–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –µ—Å–ª–∏ –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç
                try:
                    os.makedirs(persist_directory, exist_ok=True)
                    self.logger.warning(f"üìÅ [VECTOR-{self.user_id}] –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è —Å–æ–∑–¥–∞–Ω–∞ —É—Å–ø–µ—à–Ω–æ")
                except Exception as dir_error:
                    self.logger.error(f"‚ùå [VECTOR-{self.user_id}] –û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏: {dir_error}")
                    raise
                
                self.logger.debug(f"Using persist directory: {persist_directory}")
                
                self.logger.warning(f"üîß [VECTOR-{self.user_id}] –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º PersistentClient...")
                # –ò—Å–ø–æ–ª—å–∑—É–µ–º PersistentClient –¥–ª—è –Ω–∞–¥–µ–∂–Ω–æ—Å—Ç–∏
                try:
                    self.chroma_client = chromadb.PersistentClient(path=persist_directory)
                    self.logger.warning(f"‚úÖ [VECTOR-{self.user_id}] PersistentClient —Å–æ–∑–¥–∞–Ω")
                except Exception as client_error:
                    self.logger.error(f"‚ùå [VECTOR-{self.user_id}] –û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è PersistentClient: {client_error}")
                    raise
            else:
                print(f"üîß [VECTOR-{self.user_id}] –ò—Å–ø–æ–ª—å–∑—É–µ–º EphemeralClient (–≤ –ø–∞–º—è—Ç–∏)")
                # In-memory –∫–ª–∏–µ–Ω—Ç –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
                self.chroma_client = chromadb.EphemeralClient()
                print(f"‚úÖ [VECTOR-{self.user_id}] EphemeralClient —Å–æ–∑–¥–∞–Ω")
            
            self.logger.debug("ChromaDB client initialized")
            
            self.logger.info(f"üîß [VECTOR-{self.user_id}] –°–æ–∑–¥–∞–µ–º Chroma vectorstore...")
            # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º Chroma vectorstore
            try:
                # –ò—Å–ø–æ–ª—å–∑—É–µ–º –Ω–æ–≤—É—é –≤–µ—Ä—Å–∏—é Chroma –∏–∑ langchain-chroma
                try:
                    from langchain_chroma import Chroma
                    self.vectorstore = Chroma(
                        client=self.chroma_client,
                        collection_name=self.collection_name,
                        embedding_function=self.embeddings
                    )
                except ImportError:
                    # Fallback –Ω–∞ —Å—Ç–∞—Ä—É—é –≤–µ—Ä—Å–∏—é
                    from langchain.vectorstores import Chroma
                    self.vectorstore = Chroma(
                        client=self.chroma_client,
                        collection_name=self.collection_name,
                        embedding_function=self.embeddings
                    )
                self.logger.info(f"‚úÖ [VECTOR-{self.user_id}] Chroma vectorstore —Å–æ–∑–¥–∞–Ω!")
            except Exception as vs_error:
                self.logger.error(f"‚ùå [VECTOR-{self.user_id}] –û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è Chroma vectorstore: {vs_error}")
                raise
            
            self.logger.warning(f"‚úÖ [VECTOR-{self.user_id}] –í—Å–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω—ã —É—Å–ø–µ—à–Ω–æ!")
            self.logger.warning(f"üîç [VECTOR-{self.user_id}] –§–∏–Ω–∞–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞: embeddings={self.embeddings is not None}, vectorstore={self.vectorstore is not None}")
            self.logger.info("LangChain components initialized successfully")
            return True
            
        except Exception as e:
            self.logger.error(f"üí• [VECTOR-{self.user_id}] –û–®–ò–ë–ö–ê –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏: {e}")
            self.logger.error(f"üí• [VECTOR-{self.user_id}] –¢–∏–ø –æ—à–∏–±–∫–∏: {type(e).__name__}")
            self.logger.error(f"Failed to initialize LangChain components: {e}")
            self.logger.error(f"Error details: {type(e).__name__}: {str(e)}")
            
            # –ü–æ–¥—Ä–æ–±–Ω–∞—è –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞
            import traceback
            self.logger.error(f"üí• [VECTOR-{self.user_id}] –ü–æ–ª–Ω—ã–π traceback:")
            self.logger.error(traceback.format_exc())
            
            self.embeddings = None
            self.vectorstore = None
            return False
    
    def add_document(self, content: str, metadata: Dict[str, Any] = None, 
                    importance_score: float = 0.5) -> bool:
        """
        –î–æ–±–∞–≤–ª—è–µ—Ç –¥–æ–∫—É–º–µ–Ω—Ç –≤ –≤–µ–∫—Ç–æ—Ä–Ω—É—é –ø–∞–º—è—Ç—å
        
        Args:
            content: –°–æ–¥–µ—Ä–∂–∏–º–æ–µ –¥–æ–∫—É–º–µ–Ω—Ç–∞
            metadata: –ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –¥–æ–∫—É–º–µ–Ω—Ç–∞
            importance_score: –û—Ü–µ–Ω–∫–∞ –≤–∞–∂–Ω–æ—Å—Ç–∏ (0.0-1.0)
            
        Returns:
            True –µ—Å–ª–∏ –¥–æ–∫—É–º–µ–Ω—Ç –¥–æ–±–∞–≤–ª–µ–Ω —É—Å–ø–µ—à–Ω–æ
        """
        try:
            print(f"üîç [VECTOR-{self.user_id}] –î–æ–±–∞–≤–ª—è–µ–º –¥–æ–∫—É–º–µ–Ω—Ç: '{content[:50]}...' (–≤–∞–∂–Ω–æ—Å—Ç—å: {importance_score})")
            print(f"üîç [VECTOR-{self.user_id}] –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å–æ—Å—Ç–æ—è–Ω–∏–µ: vectorstore={self.vectorstore}, embeddings={self.embeddings}")
            print(f"üîç [VECTOR-{self.user_id}] –†–µ–∑—É–ª—å—Ç–∞—Ç –ø—Ä–æ–≤–µ—Ä–∫–∏: not vectorstore={not self.vectorstore}, not embeddings={not self.embeddings}")
            
            if self.vectorstore is None or self.embeddings is None:
                print(f"‚ö†Ô∏è [VECTOR-{self.user_id}] Vector store –Ω–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω!")
                self.logger.warning("Vector store or embeddings not initialized - attempting re-initialization")
                print(f"üîÑ [VECTOR-{self.user_id}] –ü—ã—Ç–∞–µ–º—Å—è –ø–µ—Ä–µ–∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å...")
                self.logger.error(f"üîÑ [VECTOR-{self.user_id}] –í–´–ó–´–í–ê–ï–ú _initialize_components()...")
                init_success = self._initialize_components()
                self.logger.error(f"üîÑ [VECTOR-{self.user_id}] _initialize_components() –≤–µ—Ä–Ω—É–ª: {init_success}")
                if init_success and self.vectorstore:
                    print(f"‚úÖ [VECTOR-{self.user_id}] –ü–µ—Ä–µ–∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —É—Å–ø–µ—à–Ω–∞")
                else:
                    print(f"‚ùå [VECTOR-{self.user_id}] –ù–µ —É–¥–∞–ª–æ—Å—å –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å! init_success={init_success}, vectorstore={self.vectorstore}")
                    return False
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –≤–∞–∂–Ω–æ—Å—Ç—å –¥–æ–∫—É–º–µ–Ω—Ç–∞
            if self.config.get('features', {}).get('importance_filtering', True):
                min_importance = self.config.get('search_settings', {}).get('min_importance', 0.3)
                print(f"üìä [VECTOR-{self.user_id}] –ü—Ä–æ–≤–µ—Ä—è–µ–º –≤–∞–∂–Ω–æ—Å—Ç—å: {importance_score} >= {min_importance}")
                if importance_score < min_importance:
                    print(f"‚ùå [VECTOR-{self.user_id}] –î–æ–∫—É–º–µ–Ω—Ç –ø—Ä–æ–ø—É—â–µ–Ω - –Ω–∏–∑–∫–∞—è –≤–∞–∂–Ω–æ—Å—Ç—å: {importance_score} < {min_importance}")
                    self.logger.debug(f"Document skipped due to low importance: {importance_score}")
                    return False
                print(f"‚úÖ [VECTOR-{self.user_id}] –í–∞–∂–Ω–æ—Å—Ç—å –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–∞: {importance_score}")
            
            # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
            doc_metadata = {
                'user_id': self.user_id,
                'created_at': datetime.utcnow().isoformat(),
                'importance_score': importance_score,
                'content_length': len(content),
                **(metadata or {})
            }
            
            # –°–æ–∑–¥–∞–µ–º Document –æ–±—ä–µ–∫—Ç
            document = Document(
                page_content=content,
                metadata=doc_metadata
            )
            
            # –î–æ–±–∞–≤–ª—è–µ–º –≤ –≤–µ–∫—Ç–æ—Ä–Ω—É—é –±–∞–∑—É
            doc_ids = self.vectorstore.add_documents([document])
            
            self.logger.debug(f"Document added to vector memory: {doc_ids[0]}")
            return True
            
        except Exception as e:
            self.logger.error(f"Failed to add document to vector memory: {e}")
            return False
    
    def search_similar(self, query: str, max_results: int = None, 
                      similarity_threshold: float = None) -> List[Dict[str, Any]]:
        """
        –ü–æ–∏—Å–∫ –ø–æ—Ö–æ–∂–∏—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –ø–æ —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–æ–º—É —Å—Ö–æ–¥—Å—Ç–≤—É
        
        Args:
            query: –ü–æ–∏—Å–∫–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å
            max_results: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
            similarity_threshold: –ü–æ—Ä–æ–≥ —Å—Ö–æ–¥—Å—Ç–≤–∞
            
        Returns:
            –°–ø–∏—Å–æ–∫ –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ —Å –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–º–∏
        """
        try:
            if not self.vectorstore:
                self.logger.warning("Vector store not initialized")
                return []
            
            # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –ø–æ–∏—Å–∫–∞ –∏–∑ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
            search_config = self.config.get('search_settings', {})
            max_results = max_results or search_config.get('max_results', 5)
            threshold = similarity_threshold or search_config.get('similarity_threshold', 0.05)
            
            print(f"üîç [VECTOR-{self.user_id}] –ü–æ–∏—Å–∫: '{query}' (–ø–æ—Ä–æ–≥: {threshold}, max: {max_results})")
            
            # –í—ã–ø–æ–ª–Ω—è–µ–º –ø–æ–∏—Å–∫ —Å –æ—Ü–µ–Ω–∫–∞–º–∏ —Å—Ö–æ–¥—Å—Ç–≤–∞
            print(f"üîç [VECTOR-{self.user_id}] –í—ã–ø–æ–ª–Ω—è–µ–º –ø–æ–∏—Å–∫ –≤ ChromaDB...")
            results = self.vectorstore.similarity_search_with_score(
                query=query,
                k=max_results
            )
            
            print(f"üîç [VECTOR-{self.user_id}] ChromaDB –≤–µ—Ä–Ω—É–ª {len(results)} —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤")
            
            # –ü–æ–ø—Ä–æ–±—É–µ–º –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–π –ø–æ–∏—Å–∫ –±–µ–∑ scores
            if not results:
                print(f"üîç [VECTOR-{self.user_id}] –ü–æ–ø—Ä–æ–±—É–µ–º –ø–æ–∏—Å–∫ –±–µ–∑ scores...")
                results_no_score = self.vectorstore.similarity_search(query, k=max_results)
                print(f"üîç [VECTOR-{self.user_id}] –ü–æ–∏—Å–∫ –±–µ–∑ scores –≤–µ—Ä–Ω—É–ª {len(results_no_score)} —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤")
                if results_no_score:
                    # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ —Ñ–æ—Ä–º–∞—Ç —Å scores
                    results = [(doc, 0.0) for doc in results_no_score]
                    print(f"üîç [VECTOR-{self.user_id}] –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä–æ–≤–∞–ª–∏ –≤ —Ñ–æ—Ä–º–∞—Ç —Å scores")
            
            # –§–∏–ª—å—Ç—Ä—É–µ–º –ø–æ –ø–æ—Ä–æ–≥—É —Å—Ö–æ–¥—Å—Ç–≤–∞ –∏ —Ñ–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
            formatted_results = []
            for i, (doc, score) in enumerate(results):
                if score == 0.0:
                    similarity = 1.0  # –ü–æ–∏—Å–∫ –±–µ–∑ scores - —Å—á–∏—Ç–∞–µ–º –∏–¥–µ–∞–ª—å–Ω—ã–º —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ–º
                else:
                    similarity = max(0.1, 1.0 - score)
                
                print(f"üîç [VECTOR-{self.user_id}] –†–µ–∑—É–ª—å—Ç–∞—Ç {i+1}: score={score}, similarity={similarity}, content='{doc.page_content[:50]}...'")
                
                if similarity >= threshold:
                    formatted_results.append({
                        'content': doc.page_content,
                        'metadata': doc.metadata,
                        'similarity_score': similarity,
                        'relevance_score': similarity,
                        'timestamp': doc.metadata.get('message_timestamp'),
                        'role': doc.metadata.get('message_role', 'unknown')
                    })
                    print(f"‚úÖ [VECTOR-{self.user_id}] –î–æ–∫—É–º–µ–Ω—Ç {i+1} –ø—Ä–æ—à–µ–ª –ø–æ—Ä–æ–≥ {threshold}")
                else:
                    print(f"‚ùå [VECTOR-{self.user_id}] –î–æ–∫—É–º–µ–Ω—Ç {i+1} –ù–ï –ø—Ä–æ—à–µ–ª –ø–æ—Ä–æ–≥ {threshold} (similarity={similarity})")
            
            print(f"üîç [VECTOR-{self.user_id}] –ò—Ç–æ–≥–æ–≤—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç: {len(formatted_results)} –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –≤—ã—à–µ –ø–æ—Ä–æ–≥–∞ {threshold}")
            self.logger.debug(f"Search found {len(formatted_results)} documents above threshold {threshold}")
            return formatted_results
            
        except Exception as e:
            self.logger.error(f"Failed to search vector memory: {e}")
            return []
    
    def search_memories(self, query: str, limit: int = 5) -> List[Dict[str, Any]]:
        """
        –ê–ª–∏–∞—Å –¥–ª—è search_similar –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏ —Å MemoryLevelsManager
        
        Args:
            query: –ü–æ–∏—Å–∫–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å
            limit: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
            
        Returns:
            –°–ø–∏—Å–æ–∫ –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö –≤–æ—Å–ø–æ–º–∏–Ω–∞–Ω–∏–π
        """
        return self.search_similar(query, max_results=limit)
    
    def _apply_temporal_decay(self, results: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """
        –ü—Ä–∏–º–µ–Ω—è–µ—Ç –≤—Ä–µ–º–µ–Ω–Ω–æ–µ –∑–∞—Ç—É—Ö–∞–Ω–∏–µ –∫ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º –ø–æ–∏—Å–∫–∞
        
        Args:
            results: –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ–∏—Å–∫–∞
            
        Returns:
            –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å —Å–∫–æ—Ä—Ä–µ–∫—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–º–∏ –æ—Ü–µ–Ω–∫–∞–º–∏
        """
        try:
            decay_config = self.config.get('temporal_decay', {})
            half_life_days = decay_config.get('half_life_days', 30)  # 30 –¥–Ω–µ–π
            
            current_time = datetime.utcnow()
            
            for result in results:
                # –ü–æ–ª—É—á–∞–µ–º –≤—Ä–µ–º—è —Å–æ–∑–¥–∞–Ω–∏—è –¥–æ–∫—É–º–µ–Ω—Ç–∞
                created_at_str = result['metadata'].get('created_at')
                if created_at_str:
                    created_at = datetime.fromisoformat(created_at_str.replace('Z', '+00:00'))
                    
                    # –í—ã—á–∏—Å–ª—è–µ–º –≤–æ–∑—Ä–∞—Å—Ç –≤ –¥–Ω—è—Ö
                    age_days = (current_time - created_at).total_seconds() / (24 * 3600)
                    
                    # –ü—Ä–∏–º–µ–Ω—è–µ–º —ç–∫—Å–ø–æ–Ω–µ–Ω—Ü–∏–∞–ª—å–Ω–æ–µ –∑–∞—Ç—É—Ö–∞–Ω–∏–µ
                    decay_factor = 0.5 ** (age_days / half_life_days)
                    
                    # –ö–æ—Ä—Ä–µ–∫—Ç–∏—Ä—É–µ–º –æ—Ü–µ–Ω–∫—É —Å—Ö–æ–¥—Å—Ç–≤–∞
                    original_score = result['similarity_score']
                    result['similarity_score'] = original_score * decay_factor
                    result['temporal_decay_factor'] = decay_factor
                    result['age_days'] = age_days
            
            return results
            
        except Exception as e:
            self.logger.warning(f"Failed to apply temporal decay: {e}")
            return results
    
    def add_message_to_memory(self, message: Message, context: MemoryContext,
                             min_importance: float = None) -> bool:
        """
        –î–æ–±–∞–≤–ª—è–µ—Ç —Å–æ–æ–±—â–µ–Ω–∏–µ –≤ –¥–æ–ª–≥–æ—Å—Ä–æ—á–Ω—É—é –≤–µ–∫—Ç–æ—Ä–Ω—É—é –ø–∞–º—è—Ç—å
        
        Args:
            message: –°–æ–æ–±—â–µ–Ω–∏–µ –¥–ª—è –¥–æ–±–∞–≤–ª–µ–Ω–∏—è
            context: –ö–æ–Ω—Ç–µ–∫—Å—Ç –ø–∞–º—è—Ç–∏
            min_importance: –ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è –≤–∞–∂–Ω–æ—Å—Ç—å –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è
            
        Returns:
            True –µ—Å–ª–∏ —Å–æ–æ–±—â–µ–Ω–∏–µ –¥–æ–±–∞–≤–ª–µ–Ω–æ
        """
        try:
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –≤–∞–∂–Ω–æ—Å—Ç—å —Å–æ–æ–±—â–µ–Ω–∏—è
            importance = self._calculate_message_importance(message, context)
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–æ—Ä–æ–≥ –≤–∞–∂–Ω–æ—Å—Ç–∏
            min_importance = min_importance or self.config.get('search_settings', {}).get('min_importance', 0.5)
            if importance < min_importance:
                return False
            
            # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
            metadata = {
                'message_role': message.role,
                'conversation_id': context.conversation_id or 'default',
                'day_number': context.day_number,
                'user_id': context.user_id,
                'message_timestamp': message.timestamp.isoformat(),
                **message.metadata
            }
            
            # –î–æ–±–∞–≤–ª—è–µ–º –≤ –≤–µ–∫—Ç–æ—Ä–Ω—É—é –ø–∞–º—è—Ç—å
            return self.add_document(
                content=message.content,
                metadata=metadata,
                importance_score=importance
            )
            
        except Exception as e:
            self.logger.error(f"Failed to add message to vector memory: {e}")
            return False
    
    def _calculate_message_importance(self, message: Message, context: MemoryContext) -> float:
        """
        –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ—Ç –≤–∞–∂–Ω–æ—Å—Ç—å —Å–æ–æ–±—â–µ–Ω–∏—è –¥–ª—è –¥–æ–ª–≥–æ—Å—Ä–æ—á–Ω–æ–≥–æ —Ö—Ä–∞–Ω–µ–Ω–∏—è
        
        Args:
            message: –°–æ–æ–±—â–µ–Ω–∏–µ
            context: –ö–æ–Ω—Ç–µ–∫—Å—Ç
            
        Returns:
            –û—Ü–µ–Ω–∫–∞ –≤–∞–∂–Ω–æ—Å—Ç–∏ (0.0-1.0)
        """
        # –ë–∞–∑–æ–≤–∞—è –≤–∞–∂–Ω–æ—Å—Ç—å –ø–æ —Ä–æ–ª–∏
        role_weights = self.config.get('importance_calculation', {}).get('role_weights', {})
        base_importance = role_weights.get(message.role, 0.5)
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ –≤–∞–∂–Ω–æ—Å—Ç–∏ - –ò–°–ü–†–ê–í–õ–ï–ù–û: —É—á–∏—Ç—ã–≤–∞–µ–º –í–°–ï –º–∞—Ä–∫–µ—Ä—ã
        importance_markers = self.config.get('importance_calculation', {}).get('importance_markers', {})
        content_lower = message.content.lower()
        
        # –ò—â–µ–º –º–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π –≤–µ—Å —Å—Ä–µ–¥–∏ –≤—Å–µ—Ö –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö –º–∞—Ä–∫–µ—Ä–æ–≤
        max_weight = 0.0
        for category, data in importance_markers.items():
            markers = data.get('markers', [])
            weight = data.get('weight', 0.0)
            
            if any(marker in content_lower for marker in markers):
                max_weight = max(max_weight, weight)
        
        base_importance += max_weight
        
        # –£—á–∏—Ç—ã–≤–∞–µ–º –¥–ª–∏–Ω—É —Å–æ–æ–±—â–µ–Ω–∏—è
        length_config = self.config.get('importance_calculation', {}).get('length_weights', {})
        content_length = len(message.content)
        
        if content_length > length_config.get('long_threshold', 200):
            base_importance += length_config.get('long_bonus', 0.1)
        elif content_length < length_config.get('short_threshold', 10):
            base_importance += length_config.get('short_penalty', -0.1)
        
        # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–π –±–æ–Ω—É—Å –¥–ª—è –ø–µ—Ä–≤—ã—Ö –¥–Ω–µ–π –æ–±—â–µ–Ω–∏—è
        if context.day_number <= 3:
            base_importance += 0.1
        
        return max(0.0, min(1.0, base_importance))
    
    def cleanup_old_documents(self, max_age_days: int = None) -> int:
        try:
            if not self.vectorstore or not self.config.get('features', {}).get('auto_cleanup', True):
                return 0
            
            max_age_days = max_age_days or self.config.get('cleanup', {}).get('max_age_days', 90)
            cutoff_date = datetime.utcnow() - timedelta(days=max_age_days)
            
            # –ü–æ–ª—É—á–∞–µ–º –≤—Å–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã –∫–æ–ª–ª–µ–∫—Ü–∏–∏
            collection = self.chroma_client.get_collection(self.collection_name)
            all_docs = collection.get(include=['metadatas'])
            
            # –ù–∞—Ö–æ–¥–∏–º –¥–æ–∫—É–º–µ–Ω—Ç—ã –¥–ª—è —É–¥–∞–ª–µ–Ω–∏—è
            docs_to_delete = []
            for doc_id, metadata in zip(all_docs['ids'], all_docs['metadatas']):
                created_at_str = metadata.get('created_at')
                if created_at_str:
                    created_at = datetime.fromisoformat(created_at_str.replace('Z', '+00:00'))
                    if created_at < cutoff_date:
                        docs_to_delete.append(doc_id)
            
            # –£–¥–∞–ª—è–µ–º —Å—Ç–∞—Ä—ã–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã
            if docs_to_delete:
                collection.delete(ids=docs_to_delete)
                self.logger.info(f"Cleaned up {len(docs_to_delete)} old documents")
            
            return len(docs_to_delete)
            
        except Exception as e:
            self.logger.error(f"Failed to cleanup old documents: {e}")
            return 0
    
    def get_memory_stats(self) -> Dict[str, Any]:
        """
        –ü–æ–ª—É—á–∞–µ—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –≤–µ–∫—Ç–æ—Ä–Ω–æ–π –ø–∞–º—è—Ç–∏
        
        Returns:
            –°–ª–æ–≤–∞—Ä—å —Å–æ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–æ–π
        """
        try:
            if not self.vectorstore:
                return {'status': 'not_initialized'}
            
            # –ü–æ–ª—É—á–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –∫–æ–ª–ª–µ–∫—Ü–∏–∏
            collection = self.chroma_client.get_collection(self.collection_name)
            collection_info = collection.get(include=['metadatas'])
            
            total_docs = len(collection_info['ids'])
            
            # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
            importance_scores = []
            content_lengths = []
            recent_docs = 0
            
            week_ago = datetime.utcnow() - timedelta(days=7)
            
            for metadata in collection_info['metadatas']:
                if 'importance_score' in metadata:
                    importance_scores.append(metadata['importance_score'])
                if 'content_length' in metadata:
                    content_lengths.append(metadata['content_length'])
                
                created_at_str = metadata.get('created_at')
                if created_at_str:
                    created_at = datetime.fromisoformat(created_at_str.replace('Z', '+00:00'))
                    if created_at > week_ago:
                        recent_docs += 1
            
            return {
                'status': 'active',
                'total_documents': total_docs,
                'recent_documents_7d': recent_docs,
                'avg_importance': sum(importance_scores) / len(importance_scores) if importance_scores else 0,
                'avg_content_length': sum(content_lengths) / len(content_lengths) if content_lengths else 0,
                'collection_name': self.collection_name,
                'config': {
                    'embedding_model': self.config.get('embedding_model'),
                    'max_results': self.config.get('search_settings', {}).get('max_results'),
                    'similarity_threshold': self.config.get('search_settings', {}).get('similarity_threshold')
                }
            }
            
        except Exception as e:
            self.logger.error(f"Failed to get memory stats: {e}")
            return {'status': 'error', 'error': str(e)}


# –§—É–Ω–∫—Ü–∏—è-—Ñ–∞–±—Ä–∏–∫–∞ –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç—É–∞–ª—å–Ω–æ–π –≤–µ–∫—Ç–æ—Ä–Ω–æ–π –ø–∞–º—è—Ç–∏
def create_intelligent_vector_memory(user_id: str, collection_name: Optional[str] = None) -> IntelligentVectorMemory:
    """
    –°–æ–∑–¥–∞–µ—Ç —ç–∫–∑–µ–º–ø–ª—è—Ä –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç—É–∞–ª—å–Ω–æ–π –≤–µ–∫—Ç–æ—Ä–Ω–æ–π –ø–∞–º—è—Ç–∏
    
    Args:
        user_id: –ò–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ç–æ—Ä –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
        collection_name: –ò–º—è –∫–æ–ª–ª–µ–∫—Ü–∏–∏
        
    Returns:
        –≠–∫–∑–µ–º–ø–ª—è—Ä –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç—É–∞–ª—å–Ω–æ–π –≤–µ–∫—Ç–æ—Ä–Ω–æ–π –ø–∞–º—è—Ç–∏
    """
    return IntelligentVectorMemory(user_id, collection_name)
