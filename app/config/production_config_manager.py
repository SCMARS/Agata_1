"""
Production-ready –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–∏–π –∑–∞–≥—Ä—É–∑—á–∏–∫ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ –±–µ–∑ —Ö–∞—Ä–¥–∫–æ–¥–∞
–ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç connection pool, hot-reload, –ø–æ—Ç–æ–∫–æ–±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å
"""
import os
import json
import yaml
import time
import logging
import threading
import select
from typing import Dict, Any, Optional, List, Union, Callable
from datetime import datetime, timedelta
from pathlib import Path
from dataclasses import dataclass, field
from collections import defaultdict
from threading import Lock, Thread
import weakref

# –ò–º–ø–æ—Ä—Ç—ã –¥–ª—è –ë–î —Å fallback
try:
    import psycopg2
    import psycopg2.extras
    import psycopg2.pool
    from psycopg2.extensions import ISOLATION_LEVEL_AUTOCOMMIT
    DB_AVAILABLE = True
except ImportError:
    DB_AVAILABLE = False
    psycopg2 = None

logger = logging.getLogger(__name__)


@dataclass
class CacheEntry:
    """–≠–ª–µ–º–µ–Ω—Ç –∫–µ—à–∞ —Å TTL"""
    value: Any
    created_at: datetime
    ttl_seconds: int
    namespace: str = 'default'
    
    @property
    def is_expired(self) -> bool:
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –∏—Å—Ç–µ–∫ –ª–∏ TTL"""
        return datetime.now() > self.created_at + timedelta(seconds=self.ttl_seconds)


@dataclass
class ConfigManagerConfig:
    """–ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è —Å–∞–º–æ–≥–æ –º–µ–Ω–µ–¥–∂–µ—Ä–∞ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏"""
    # –ò—Å—Ç–æ—á–Ω–∏–∫–∏ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
    config_dir: str = field(default_factory=lambda: os.getenv('CONFIG_DIR', './app/config'))
    file_patterns: List[str] = field(default_factory=lambda: ['*.yml', '*.yaml', '*.json'])
    
    # –ë–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö
    db_connection_string: Optional[str] = field(default_factory=lambda: os.getenv('DATABASE_URL'))
    db_pool_min_connections: int = field(default_factory=lambda: int(os.getenv('DB_POOL_MIN', '2')))
    db_pool_max_connections: int = field(default_factory=lambda: int(os.getenv('DB_POOL_MAX', '10')))
    db_connect_timeout: int = field(default_factory=lambda: int(os.getenv('DB_CONNECT_TIMEOUT', '10')))
    
    # –ö–µ—à–∏—Ä–æ–≤–∞–Ω–∏–µ
    cache_ttl_seconds: int = field(default_factory=lambda: int(os.getenv('CONFIG_CACHE_TTL', '300')))
    cache_max_size: int = field(default_factory=lambda: int(os.getenv('CONFIG_CACHE_MAX_SIZE', '1000')))
    
    # Hot-reload
    auto_reload: bool = field(default_factory=lambda: os.getenv('CONFIG_AUTO_RELOAD', 'true').lower() == 'true')
    file_watch_enabled: bool = field(default_factory=lambda: os.getenv('CONFIG_FILE_WATCH', 'true').lower() == 'true')
    db_listen_channel: str = field(default_factory=lambda: os.getenv('CONFIG_LISTEN_CHANNEL', 'memory_config_updates'))
    
    # –û–∫—Ä—É–∂–µ–Ω–∏–µ
    environment: str = field(default_factory=lambda: os.getenv('APP_ENVIRONMENT', 'production'))
    env_prefix: str = field(default_factory=lambda: os.getenv('CONFIG_ENV_PREFIX', 'MEMORY'))
    env_separator: str = '__'
    
    # –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ
    log_level: str = field(default_factory=lambda: os.getenv('CONFIG_LOG_LEVEL', 'INFO'))
    log_config_access: bool = field(default_factory=lambda: os.getenv('CONFIG_LOG_ACCESS', 'false').lower() == 'true')
    mask_secrets: bool = field(default_factory=lambda: os.getenv('CONFIG_MASK_SECRETS', 'true').lower() == 'true')
    
    # –ú–µ—Ç—Ä–∏–∫–∏
    metrics_enabled: bool = field(default_factory=lambda: os.getenv('CONFIG_METRICS_ENABLED', 'true').lower() == 'true')


class ConfigCache:
    """–ü–æ—Ç–æ–∫–æ–±–µ–∑–æ–ø–∞—Å–Ω—ã–π –∫–µ—à —Å TTL –∏ namespace support"""
    
    def __init__(self, max_size: int = 1000):
        self._cache: Dict[str, CacheEntry] = {}
        self._access_times: Dict[str, datetime] = {}
        self._lock = Lock()
        self._max_size = max_size
    
    def get(self, key: str, namespace: str = 'default') -> Optional[Any]:
        """–ü–æ–ª—É—á–∞–µ—Ç –∑–Ω–∞—á–µ–Ω–∏–µ –∏–∑ –∫–µ—à–∞"""
        cache_key = f"{namespace}:{key}"
        
        with self._lock:
            entry = self._cache.get(cache_key)
            if not entry:
                return None
            
            if entry.is_expired:
                del self._cache[cache_key]
                if cache_key in self._access_times:
                    del self._access_times[cache_key]
                return None
            
            self._access_times[cache_key] = datetime.now()
            return entry.value
    
    def set(self, key: str, value: Any, ttl_seconds: int, namespace: str = 'default') -> None:
        """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç –∑–Ω–∞—á–µ–Ω–∏–µ –≤ –∫–µ—à–µ"""
        cache_key = f"{namespace}:{key}"
        
        with self._lock:
            # –û—á–∏—Å—Ç–∫–∞ –ø–µ—Ä–µ–ø–æ–ª–Ω–µ–Ω–Ω–æ–≥–æ –∫–µ—à–∞
            if len(self._cache) >= self._max_size:
                self._evict_lru()
            
            self._cache[cache_key] = CacheEntry(
                value=value,
                created_at=datetime.now(),
                ttl_seconds=ttl_seconds,
                namespace=namespace
            )
            self._access_times[cache_key] = datetime.now()
    
    def invalidate(self, key: Optional[str] = None, namespace: Optional[str] = None) -> int:
        """–ò–Ω–≤–∞–ª–∏–¥–∏—Ä—É–µ—Ç –∫–µ—à –ø–æ –∫–ª—é—á—É –∏–ª–∏ namespace"""
        removed_count = 0
        
        with self._lock:
            if key and namespace:
                # –ò–Ω–≤–∞–ª–∏–¥–∞—Ü–∏—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ –∫–ª—é—á–∞
                cache_key = f"{namespace}:{key}"
                if cache_key in self._cache:
                    del self._cache[cache_key]
                    if cache_key in self._access_times:
                        del self._access_times[cache_key]
                    removed_count = 1
                    
            elif namespace:
                # –ò–Ω–≤–∞–ª–∏–¥–∞—Ü–∏—è –≤—Å–µ–≥–æ namespace
                keys_to_remove = [k for k in self._cache.keys() if k.startswith(f"{namespace}:")]
                for cache_key in keys_to_remove:
                    del self._cache[cache_key]
                    if cache_key in self._access_times:
                        del self._access_times[cache_key]
                    removed_count += 1
                    
            else:
                # –ü–æ–ª–Ω–∞—è –æ—á–∏—Å—Ç–∫–∞ –∫–µ—à–∞
                removed_count = len(self._cache)
                self._cache.clear()
                self._access_times.clear()
        
        return removed_count
    
    def _evict_lru(self) -> None:
        """–£–¥–∞–ª—è–µ—Ç –Ω–∞–∏–º–µ–Ω–µ–µ –Ω–µ–¥–∞–≤–Ω–æ –∏—Å–ø–æ–ª—å–∑—É–µ–º—ã–µ —ç–ª–µ–º–µ–Ω—Ç—ã"""
        if not self._access_times:
            return
        
        # –£–¥–∞–ª—è–µ–º 10% —Å–∞–º—ã—Ö —Å—Ç–∞—Ä—ã—Ö —ç–ª–µ–º–µ–Ω—Ç–æ–≤
        sorted_by_access = sorted(self._access_times.items(), key=lambda x: x[1])
        to_remove = max(1, len(sorted_by_access) // 10)
        
        for cache_key, _ in sorted_by_access[:to_remove]:
            if cache_key in self._cache:
                del self._cache[cache_key]
            del self._access_times[cache_key]
    
    def get_stats(self) -> Dict[str, Any]:
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –∫–µ—à–∞"""
        with self._lock:
            expired_count = sum(1 for entry in self._cache.values() if entry.is_expired)
            namespaces = defaultdict(int)
            for key in self._cache.keys():
                namespace = key.split(':', 1)[0]
                namespaces[namespace] += 1
            
            return {
                'total_entries': len(self._cache),
                'expired_entries': expired_count,
                'max_size': self._max_size,
                'namespaces': dict(namespaces)
            }


class ProductionConfigManager:
    """Production-ready –º–µ–Ω–µ–¥–∂–µ—Ä –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏"""
    
    def __init__(self, config: Optional[ConfigManagerConfig] = None):
        self.config = config or ConfigManagerConfig()
        
        # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
        logging.basicConfig(level=getattr(logging, self.config.log_level.upper()))
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤
        self._cache = ConfigCache(self.config.cache_max_size)
        self._db_pool: Optional[psycopg2.pool.ThreadedConnectionPool] = None
        self._fallback_configs: Dict[str, Dict[str, Any]] = {}
        self._file_watchers: Dict[str, float] = {}  # file_path -> last_modified
        
        # –£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –ø–æ—Ç–æ–∫–∞–º–∏
        self._shutdown_event = threading.Event()
        self._reload_thread: Optional[Thread] = None
        self._listener_thread: Optional[Thread] = None
        
        # Callback –¥–ª—è —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–π –æ–± –∏–∑–º–µ–Ω–µ–Ω–∏—è—Ö
        self._change_callbacks: List[Callable[[str, Dict[str, Any]], None]] = []
        
        # –ú–µ—Ç—Ä–∏–∫–∏
        self._metrics = {
            'config_requests': 0,
            'cache_hits': 0,
            'cache_misses': 0,
            'db_fallbacks': 0,
            'file_fallbacks': 0,
            'hot_reloads': 0,
            'errors': 0
        }
        self._metrics_lock = Lock()
        
        logger.info(f"Initializing ProductionConfigManager for environment: {self.config.environment}")
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è
        self._initialize()
    
    def _initialize(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–µ–Ω–µ–¥–∂–µ—Ä–∞"""
        try:
            # 1. –ó–∞–≥—Ä—É–∂–∞–µ–º fallback –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ –∏–∑ —Ñ–∞–π–ª–æ–≤
            self._load_fallback_configs()
            
            # 2. –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ –ë–î
            if DB_AVAILABLE and self.config.db_connection_string:
                self._init_db_pool()
            else:
                logger.warning("Database not available or not configured, using file-only mode")
            
            # 3. –ó–∞–ø—É—Å–∫–∞–µ–º hot-reload –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
            if self.config.auto_reload:
                self._start_auto_reload()
            
            logger.info("ProductionConfigManager initialized successfully")
            
        except Exception as e:
            logger.error(f"Failed to initialize ConfigManager: {e}")
            self._record_error("initialization_failed", str(e))
            # –ù–µ –ø–∞–¥–∞–µ–º, —Ä–∞–±–æ—Ç–∞–µ–º –≤ —Ä–µ–∂–∏–º–µ fallback
    
    def _load_fallback_configs(self):
        """–ó–∞–≥—Ä—É–∂–∞–µ—Ç fallback –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ –∏–∑ —Ñ–∞–π–ª–æ–≤"""
        config_dir = Path(self.config.config_dir)
        
        if not config_dir.exists():
            logger.warning(f"Config directory not found: {config_dir}")
            return
        
        loaded_count = 0
        
        for pattern in self.config.file_patterns:
            for config_file in config_dir.glob(pattern):
                try:
                    with open(config_file, 'r', encoding='utf-8') as f:
                        if config_file.suffix.lower() in ['.yml', '.yaml']:
                            data = yaml.safe_load(f)
                        else:
                            data = json.load(f)
                    
                    if data:
                        config_key = config_file.stem
                        self._fallback_configs[config_key] = data
                        self._file_watchers[str(config_file)] = config_file.stat().st_mtime
                        loaded_count += 1
                        
                        logger.debug(f"Loaded fallback config: {config_key}")
                        
                except Exception as e:
                    logger.error(f"Failed to load config file {config_file}: {e}")
                    self._record_error("file_load_failed", str(e))
        
        logger.info(f"Loaded {loaded_count} fallback configuration files")
    
    def _init_db_pool(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ—Ç –ø—É–ª –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–π –∫ –ë–î"""
        try:
            self._db_pool = psycopg2.pool.ThreadedConnectionPool(
                minconn=self.config.db_pool_min_connections,
                maxconn=self.config.db_pool_max_connections,
                dsn=self.config.db_connection_string,
                connect_timeout=self.config.db_connect_timeout
            )
            
            # –¢–µ—Å—Ç–∏—Ä—É–µ–º –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ
            with self._get_db_connection() as conn:
                with conn.cursor() as cur:
                    cur.execute("SELECT 1")
            
            logger.info(f"Database pool initialized: {self.config.db_pool_min_connections}-{self.config.db_pool_max_connections} connections")
            
        except Exception as e:
            logger.error(f"Failed to initialize database pool: {e}")
            self._record_error("db_pool_init_failed", str(e))
            self._db_pool = None
    
    def _get_db_connection(self):
        """–ü–æ–ª—É—á–∞–µ—Ç –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∏–∑ –ø—É–ª–∞"""
        if not self._db_pool:
            raise RuntimeError("Database pool not available")
        
        return self._db_pool.getconn()
    
    def _return_db_connection(self, conn, close=False):
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –≤ –ø—É–ª"""
        if self._db_pool and conn:
            self._db_pool.putconn(conn, close=close)
    
    def _start_auto_reload(self):
        """–ó–∞–ø—É—Å–∫–∞–µ—Ç auto-reload –ø–æ—Ç–æ–∫–∏"""
        if self.config.file_watch_enabled:
            self._reload_thread = Thread(
                target=self._file_watch_loop,
                name="ConfigFileWatcher",
                daemon=True
            )
            self._reload_thread.start()
            logger.info("File watcher thread started")
        
        if self._db_pool and self.config.db_listen_channel:
            self._listener_thread = Thread(
                target=self._db_listen_loop,
                name="ConfigDBListener", 
                daemon=True
            )
            self._listener_thread.start()
            logger.info(f"Database listener thread started for channel: {self.config.db_listen_channel}")
    
    def _file_watch_loop(self):
        """–¶–∏–∫–ª –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏—è –∏–∑–º–µ–Ω–µ–Ω–∏–π —Ñ–∞–π–ª–æ–≤"""
        logger.debug("File watch loop started")
        
        while not self._shutdown_event.is_set():
            try:
                for file_path, last_mtime in list(self._file_watchers.items()):
                    path = Path(file_path)
                    if path.exists():
                        current_mtime = path.stat().st_mtime
                        if current_mtime > last_mtime:
                            logger.info(f"Config file changed: {file_path}")
                            self._reload_file_config(path)
                            self._file_watchers[file_path] = current_mtime
                            self._record_metric('hot_reloads')
                
                time.sleep(5)  # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–∞–∂–¥—ã–µ 5 —Å–µ–∫—É–Ω–¥
                
            except Exception as e:
                logger.error(f"File watch error: {e}")
                self._record_error("file_watch_error", str(e))
                time.sleep(10)  # –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º –∏–Ω—Ç–µ—Ä–≤–∞–ª –ø—Ä–∏ –æ—à–∏–±–∫–µ
    
    def _db_listen_loop(self):
        """–¶–∏–∫–ª –ø—Ä–æ—Å–ª—É—à–∏–≤–∞–Ω–∏—è –∏–∑–º–µ–Ω–µ–Ω–∏–π –≤ –ë–î"""
        logger.debug("Database listen loop started")
        
        conn = None
        try:
            conn = self._get_db_connection()
            conn.set_isolation_level(ISOLATION_LEVEL_AUTOCOMMIT)
            
            with conn.cursor() as cur:
                cur.execute(f"LISTEN {self.config.db_listen_channel}")
                logger.info(f"Listening for notifications on channel: {self.config.db_listen_channel}")
                
                while not self._shutdown_event.is_set():
                    if select.select([conn], [], [], 5) == ([], [], []):
                        continue  # Timeout, –ø—Ä–æ–≤–µ—Ä—è–µ–º shutdown_event
                    
                    conn.poll()
                    while conn.notifies:
                        notify = conn.notifies.pop(0)
                        logger.info(f"Received config change notification: {notify.payload}")
                        
                        try:
                            # –ü–∞—Ä—Å–∏–º payload (–æ–∂–∏–¥–∞–µ–º JSON —Å config_key)
                            if notify.payload:
                                payload = json.loads(notify.payload)
                                config_key = payload.get('config_key')
                                if config_key:
                                    self._invalidate_config_cache(config_key)
                                    self._record_metric('hot_reloads')
                        except json.JSONDecodeError:
                            # –ï—Å–ª–∏ –Ω–µ JSON, —Å—á–∏—Ç–∞–µ–º —á—Ç–æ —ç—Ç–æ config_key
                            self._invalidate_config_cache(notify.payload)
                            self._record_metric('hot_reloads')
                        except Exception as e:
                            logger.error(f"Error processing notification: {e}")
                            self._record_error("notification_processing_error", str(e))
                            
        except Exception as e:
            logger.error(f"Database listen error: {e}")
            self._record_error("db_listen_error", str(e))
        finally:
            if conn:
                try:
                    with conn.cursor() as cur:
                        cur.execute(f"UNLISTEN {self.config.db_listen_channel}")
                except:
                    pass
                self._return_db_connection(conn, close=True)
    
    def _reload_file_config(self, file_path: Path):
        """–ü–µ—Ä–µ–∑–∞–≥—Ä—É–∂–∞–µ—Ç –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é –∏–∑ —Ñ–∞–π–ª–∞"""
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                if file_path.suffix.lower() in ['.yml', '.yaml']:
                    data = yaml.safe_load(f)
                else:
                    data = json.load(f)
            
            if data:
                config_key = file_path.stem
                old_config = self._fallback_configs.get(config_key, {})
                self._fallback_configs[config_key] = data
                
                # –ò–Ω–≤–∞–ª–∏–¥–∏—Ä—É–µ–º –∫–µ—à –¥–ª—è —ç—Ç–æ–π –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
                self._invalidate_config_cache(config_key)
                
                # –£–≤–µ–¥–æ–º–ª—è–µ–º –ø–æ–¥–ø–∏—Å—á–∏–∫–æ–≤
                self._notify_config_change(config_key, data)
                
                logger.info(f"Reloaded config: {config_key}")
                
        except Exception as e:
            logger.error(f"Failed to reload config from {file_path}: {e}")
            self._record_error("config_reload_failed", str(e))
    
    def _invalidate_config_cache(self, config_key: str):
        """–ò–Ω–≤–∞–ª–∏–¥–∏—Ä—É–µ—Ç –∫–µ—à –¥–ª—è –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏"""
        removed_count = self._cache.invalidate(namespace=config_key)
        logger.debug(f"Invalidated {removed_count} cache entries for config: {config_key}")
    
    def _notify_config_change(self, config_key: str, new_config: Dict[str, Any]):
        """–£–≤–µ–¥–æ–º–ª—è–µ—Ç –ø–æ–¥–ø–∏—Å—á–∏–∫–æ–≤ –æ–± –∏–∑–º–µ–Ω–µ–Ω–∏–∏ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏"""
        for callback in self._change_callbacks:
            try:
                callback(config_key, new_config)
            except Exception as e:
                logger.error(f"Config change callback error: {e}")
    
    def get_config(self, 
                   config_key: str, 
                   user_id: Optional[str] = None,
                   default: Any = None,
                   force_reload: bool = False) -> Dict[str, Any]:
        """
        –ü–æ–ª—É—á–∞–µ—Ç –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é —Å —É—á–µ—Ç–æ–º –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–æ–≤:
        1. –ü–µ—Ä–µ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è
        2. –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –∏–∑ –ë–î
        3. –ì–ª–æ–±–∞–ª—å–Ω–∞—è –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –∏–∑ –ë–î
        4. Fallback –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –∏–∑ —Ñ–∞–π–ª–æ–≤
        """
        self._record_metric('config_requests')
        
        if self.config.log_config_access:
            logger.debug(f"Getting config: {config_key} for user: {user_id}")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–µ—à
        cache_key = f"{config_key}:{user_id or 'global'}"
        if not force_reload:
            cached_value = self._cache.get(cache_key, namespace=config_key)
            if cached_value is not None:
                self._record_metric('cache_hits')
                return cached_value
        
        self._record_metric('cache_misses')
        
        # –°–æ–±–∏—Ä–∞–µ–º –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é –∏–∑ –≤—Å–µ—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤
        final_config = {}
        
        # 1. –ë–∞–∑–æ–≤–∞—è –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –∏–∑ —Ñ–∞–π–ª–æ–≤
        file_config = self._fallback_configs.get(config_key, {})
        if file_config:
            final_config.update(file_config)
        
        # 2. –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –∏–∑ –ë–î
        db_config = self._load_config_from_db(config_key, user_id)
        if db_config:
            final_config = self._deep_merge(final_config, db_config)
        elif self._db_pool:
            # –ë–∞–∑–∞ –¥–æ—Å—Ç—É–ø–Ω–∞, –Ω–æ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ –Ω–µ—Ç
            pass
        else:
            # –ë–∞–∑–∞ –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞, –∏—Å–ø–æ–ª—å–∑—É–µ–º fallback
            self._record_metric('db_fallbacks')
        
        # 3. –ü–µ—Ä–µ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –∏–∑ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è
        env_overrides = self._get_env_overrides(config_key)
        if env_overrides:
            final_config = self._deep_merge(final_config, env_overrides)
        
        # –ï—Å–ª–∏ –Ω–∏—á–µ–≥–æ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ, –∏—Å–ø–æ–ª—å–∑—É–µ–º default
        if not final_config and default is not None:
            final_config = default if isinstance(default, dict) else {'default': default}
        
        # –ö–µ—à–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
        if final_config:
            self._cache.set(cache_key, final_config, self.config.cache_ttl_seconds, namespace=config_key)
        
        # –ú–∞—Å–∫–∏—Ä—É–µ–º —Å–µ–∫—Ä–µ—Ç—ã –≤ –ª–æ–≥–∞—Ö
        if self.config.log_config_access:
            safe_config = self._mask_secrets(final_config) if self.config.mask_secrets else final_config
            logger.debug(f"Resolved config for {config_key}: {safe_config}")
        
        return final_config
    
    def _load_config_from_db(self, config_key: str, user_id: Optional[str]) -> Optional[Dict[str, Any]]:
        """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é –∏–∑ –ë–î"""
        if not self._db_pool:
            return None
        
        conn = None
        try:
            conn = self._get_db_connection()
            
            with conn.cursor(cursor_factory=psycopg2.extras.RealDictCursor) as cur:
                # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ñ—É–Ω–∫—Ü–∏—é get_effective_config –∏–∑ –ë–î
                cur.execute("""
                    SELECT get_effective_config(%s, %s, %s) as config
                """, (config_key, user_id, self.config.environment))
                
                result = cur.fetchone()
                if result and result['config']:
                    return dict(result['config'])
                    
        except Exception as e:
            logger.error(f"Database config load error for {config_key}: {e}")
            self._record_error("db_config_load_error", str(e))
        finally:
            if conn:
                self._return_db_connection(conn)
        
        return None
    
    def _get_env_overrides(self, config_key: str) -> Dict[str, Any]:
        """–ü–æ–ª—É—á–∞–µ—Ç –ø–µ—Ä–µ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –∏–∑ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è"""
        overrides = {}
        
        # –ò—â–µ–º –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –≤–∏–¥–∞ PREFIX__CONFIG_KEY__PARAM__SUBPARAM=value
        env_prefix = f"{self.config.env_prefix}{self.config.env_separator}{config_key.upper()}{self.config.env_separator}"
        
        for env_var, value in os.environ.items():
            if env_var.startswith(env_prefix):
                # –ü–æ–ª—É—á–∞–µ–º –ø—É—Ç—å –ø–∞—Ä–∞–º–µ—Ç—Ä–∞
                param_path = env_var[len(env_prefix):].lower()
                
                # –ó–∞–º–µ–Ω—è–µ–º __ –Ω–∞ . –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –≤–ª–æ–∂–µ–Ω–Ω–æ–π —Å—Ç—Ä—É–∫—Ç—É—Ä—ã
                param_path = param_path.replace(self.config.env_separator.lower(), '.')
                
                # –ü–∞—Ä—Å–∏–º –∑–Ω–∞—á–µ–Ω–∏–µ
                typed_value = self._parse_env_value(value)
                
                # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –∑–Ω–∞—á–µ–Ω–∏–µ –ø–æ –ø—É—Ç–∏
                self._set_nested_value(overrides, param_path, typed_value)
        
        return overrides
    
    def _parse_env_value(self, value: str) -> Union[str, int, float, bool, dict, list, None]:
        """–ü–∞—Ä—Å–∏—Ç –∑–Ω–∞—á–µ–Ω–∏–µ –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π –æ–∫—Ä—É–∂–µ–Ω–∏—è –≤ –ø—Ä–∞–≤–∏–ª—å–Ω—ã–π —Ç–∏–ø"""
        # –ü—É—Å—Ç–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ
        if not value:
            return None
        
        # Boolean
        if value.lower() in ('true', 'false'):
            return value.lower() == 'true'
        
        # None/null
        if value.lower() in ('null', 'none', 'nil'):
            return None
        
        # JSON (–º–∞—Å—Å–∏–≤—ã –∏ –æ–±—ä–µ–∫—Ç—ã)
        if (value.startswith('[') and value.endswith(']')) or (value.startswith('{') and value.endswith('}')):
            try:
                return json.loads(value)
            except json.JSONDecodeError:
                pass  # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –∫–∞–∫ —Å—Ç—Ä–æ–∫—É
        
        # –ß–∏—Å–ª–∞
        try:
            if '.' in value or 'e' in value.lower():
                return float(value)
            else:
                return int(value)
        except ValueError:
            pass
        
        # –°—Ç—Ä–æ–∫–∞ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é)
        return value
    
    def _set_nested_value(self, config: Dict[str, Any], path: str, value: Any):
        """–£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ—Ç –∑–Ω–∞—á–µ–Ω–∏–µ –ø–æ –≤–ª–æ–∂–µ–Ω–Ω–æ–º—É –ø—É—Ç–∏"""
        keys = path.split('.')
        current = config
        
        for key in keys[:-1]:
            if key not in current:
                current[key] = {}
            elif not isinstance(current[key], dict):
                # –ö–æ–Ω—Ñ–ª–∏–∫—Ç —Ç–∏–ø–æ–≤, –ø–µ—Ä–µ–∑–∞–ø–∏—Å—ã–≤–∞–µ–º
                current[key] = {}
            current = current[key]
        
        current[keys[-1]] = value
    
    def _deep_merge(self, base: Dict[str, Any], override: Dict[str, Any]) -> Dict[str, Any]:
        """–ì–ª—É–±–æ–∫–æ –æ–±—ä–µ–¥–∏–Ω—è–µ—Ç –¥–≤–∞ —Å–ª–æ–≤–∞—Ä—è"""
        result = base.copy()
        
        for key, value in override.items():
            if (key in result and 
                isinstance(result[key], dict) and 
                isinstance(value, dict)):
                result[key] = self._deep_merge(result[key], value)
            else:
                result[key] = value
        
        return result
    
    def _mask_secrets(self, config: Dict[str, Any]) -> Dict[str, Any]:
        """–ú–∞—Å–∫–∏—Ä—É–µ—Ç —Å–µ–∫—Ä–µ—Ç–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è –≤ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏"""
        secret_keys = {
            'password', 'passwd', 'secret', 'key', 'token', 
            'api_key', 'private_key', 'access_token', 'auth_token'
        }
        
        def mask_dict(d):
            if not isinstance(d, dict):
                return d
            
            result = {}
            for k, v in d.items():
                key_lower = k.lower()
                if any(secret_word in key_lower for secret_word in secret_keys):
                    result[k] = '***MASKED***'
                elif isinstance(v, dict):
                    result[k] = mask_dict(v)
                elif isinstance(v, list):
                    result[k] = [mask_dict(item) if isinstance(item, dict) else item for item in v]
                else:
                    result[k] = v
            return result
        
        return mask_dict(config)
    
    def _record_metric(self, metric_name: str, value: float = 1.0):
        """–ó–∞–ø–∏—Å—ã–≤–∞–µ—Ç –º–µ—Ç—Ä–∏–∫—É"""
        with self._metrics_lock:
            self._metrics[metric_name] = self._metrics.get(metric_name, 0) + value
        
        # –û–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ –∑–∞–ø–∏—Å—ã–≤–∞–µ–º –≤ –ë–î
        if self.config.metrics_enabled and self._db_pool:
            self._record_db_metric('config_manager', metric_name, value)
    
    def _record_error(self, error_type: str, error_message: str):
        """–ó–∞–ø–∏—Å—ã–≤–∞–µ—Ç –æ—à–∏–±–∫—É"""
        self._record_metric('errors')
        
        if self.config.metrics_enabled and self._db_pool:
            self._record_db_metric('config_manager_error', error_type, 1.0, {
                'error_message': error_message,
                'environment': self.config.environment
            })
    
    def _record_db_metric(self, metric_type: str, metric_name: str, value: float, context: Optional[Dict] = None):
        """–ó–∞–ø–∏—Å—ã–≤–∞–µ—Ç –º–µ—Ç—Ä–∏–∫—É –≤ –ë–î"""
        conn = None
        try:
            conn = self._get_db_connection()
            
            with conn.cursor() as cur:
                cur.execute("""
                    INSERT INTO memory_metrics (metric_type, metric_name, metric_value, context, environment)
                    VALUES (%s, %s, %s, %s, %s)
                """, (metric_type, metric_name, value, json.dumps(context) if context else None, self.config.environment))
                
                conn.commit()
                
        except Exception as e:
            # –ù–µ –ª–æ–≥–∏—Ä—É–µ–º –æ—à–∏–±–∫–∏ –∑–∞–ø–∏—Å–∏ –º–µ—Ç—Ä–∏–∫ —á—Ç–æ–±—ã –∏–∑–±–µ–∂–∞—Ç—å —Ü–∏–∫–ª–æ–≤
            pass
        finally:
            if conn:
                self._return_db_connection(conn)
    
    def set_user_config(self, user_id: str, config_key: str, config_value: Dict[str, Any], 
                       expires_hours: Optional[int] = None) -> bool:
        """–£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫—É—é –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é"""
        if not self._db_pool:
            logger.warning("Cannot set user config: database not available")
            return False
        
        conn = None
        try:
            expires_at = None
            if expires_hours:
                expires_at = datetime.now() + timedelta(hours=expires_hours)
            
            conn = self._get_db_connection()
            
            with conn.cursor() as cur:
                cur.execute("""
                    INSERT INTO user_configs (user_id, config_key, config_value, expires_at)
                    VALUES (%s, %s, %s, %s)
                    ON CONFLICT (user_id, config_key) 
                    DO UPDATE SET 
                        config_value = EXCLUDED.config_value,
                        expires_at = EXCLUDED.expires_at,
                        updated_at = NOW()
                """, (user_id, config_key, json.dumps(config_value), expires_at))
                
                conn.commit()
                
                # –ò–Ω–≤–∞–ª–∏–¥–∏—Ä—É–µ–º –∫–µ—à
                self._invalidate_config_cache(config_key)
                
                # –£–≤–µ–¥–æ–º–ª—è–µ–º —á–µ—Ä–µ–∑ NOTIFY
                cur.execute(f"""
                    NOTIFY {self.config.db_listen_channel}, %s
                """, (json.dumps({'config_key': config_key, 'user_id': user_id}),))
                
                conn.commit()
                
                logger.info(f"User config set: {user_id}:{config_key}")
                self._record_metric('user_config_updates')
                return True
                
        except Exception as e:
            logger.error(f"Set user config error: {e}")
            self._record_error("set_user_config_error", str(e))
            if conn:
                conn.rollback()
            return False
        finally:
            if conn:
                self._return_db_connection(conn)
    
    def reload_config(self, config_key: str, version: str) -> bool:
        """Hot-reload –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏"""
        if not self._db_pool:
            logger.warning("Cannot reload config: database not available")
            return False
        
        conn = None
        try:
            conn = self._get_db_connection()
            
            with conn.cursor() as cur:
                cur.execute("""
                    SELECT reload_config(%s, %s, %s)
                """, (config_key, version, self.config.environment))
                
                success = cur.fetchone()[0]
                
                if success:
                    # –ò–Ω–≤–∞–ª–∏–¥–∏—Ä—É–µ–º –∫–µ—à
                    self._invalidate_config_cache(config_key)
                    
                    # –£–≤–µ–¥–æ–º–ª—è–µ–º —á–µ—Ä–µ–∑ NOTIFY
                    cur.execute(f"""
                        NOTIFY {self.config.db_listen_channel}, %s
                    """, (json.dumps({'config_key': config_key, 'version': version}),))
                    
                    conn.commit()
                    
                    logger.info(f"Config reloaded: {config_key} v{version}")
                    self._record_metric('config_reloads')
                
                return success
                
        except Exception as e:
            logger.error(f"Config reload error: {e}")
            self._record_error("config_reload_error", str(e))
            return False
        finally:
            if conn:
                self._return_db_connection(conn)
    
    def add_change_callback(self, callback: Callable[[str, Dict[str, Any]], None]):
        """–î–æ–±–∞–≤–ª—è–µ—Ç callback –¥–ª—è —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–π –æ–± –∏–∑–º–µ–Ω–µ–Ω–∏—è—Ö"""
        self._change_callbacks.append(callback)
    
    def get_stats(self) -> Dict[str, Any]:
        """–ü–æ–ª—É—á–∞–µ—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –º–µ–Ω–µ–¥–∂–µ—Ä–∞"""
        with self._metrics_lock:
            metrics = self._metrics.copy()
        
        cache_stats = self._cache.get_stats()
        
        return {
            'environment': self.config.environment,
            'database_available': self._db_pool is not None,
            'auto_reload_enabled': self.config.auto_reload,
            'cache_stats': cache_stats,
            'metrics': metrics,
            'fallback_configs_count': len(self._fallback_configs),
            'file_watchers_count': len(self._file_watchers),
            'change_callbacks_count': len(self._change_callbacks)
        }
    
    def shutdown(self):
        """–ö–æ—Ä—Ä–µ–∫—Ç–Ω–æ–µ –∑–∞–≤–µ—Ä—à–µ–Ω–∏–µ —Ä–∞–±–æ—Ç—ã"""
        logger.info("Shutting down ProductionConfigManager")
        
        # –û—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –ø–æ—Ç–æ–∫–∏
        self._shutdown_event.set()
        
        if self._reload_thread and self._reload_thread.is_alive():
            self._reload_thread.join(timeout=5)
        
        if self._listener_thread and self._listener_thread.is_alive():
            self._listener_thread.join(timeout=5)
        
        # –ó–∞–∫—Ä—ã–≤–∞–µ–º –ø—É–ª —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–π
        if self._db_pool:
            self._db_pool.closeall()
        
        logger.info("ProductionConfigManager shutdown completed")


# –ì–ª–æ–±–∞–ª—å–Ω—ã–π —ç–∫–∑–µ–º–ø–ª—è—Ä –º–µ–Ω–µ–¥–∂–µ—Ä–∞
config_manager = ProductionConfigManager()

# –†–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏—è –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ–≥–æ –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è
import atexit
atexit.register(config_manager.shutdown)


# –£–¥–æ–±–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏ –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ –¥–æ—Å—Ç—É–ø–∞
def get_config(config_key: str, user_id: Optional[str] = None, default: Any = None) -> Dict[str, Any]:
    """–ë—ã—Å—Ç—Ä—ã–π –¥–æ—Å—Ç—É–ø –∫ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏"""
    return config_manager.get_config(config_key, user_id, default)


def get_memory_thresholds(user_id: Optional[str] = None) -> Dict[str, float]:
    """–ë—ã—Å—Ç—Ä—ã–π –¥–æ—Å—Ç—É–ø –∫ –ø–æ—Ä–æ–≥–∞–º –ø–∞–º—è—Ç–∏"""
    return config_manager.get_config('memory_thresholds', user_id, {})


def get_search_weights(user_id: Optional[str] = None) -> Dict[str, float]:
    """–ë—ã—Å—Ç—Ä—ã–π –¥–æ—Å—Ç—É–ø –∫ –≤–µ—Å–∞–º –ø–æ–∏—Å–∫–∞"""
    return config_manager.get_config('search_weights', user_id, {})


def reload_config(config_key: str, version: str) -> bool:
    """–ë—ã—Å—Ç—Ä—ã–π hot-reload –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏"""
    return config_manager.reload_config(config_key, version)


if __name__ == "__main__":
    # –¢–µ—Å—Ç –º–µ–Ω–µ–¥–∂–µ—Ä–∞ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
    print("üß™ Testing ProductionConfigManager")
    
    # –°–æ–∑–¥–∞–µ–º —Ç–µ—Å—Ç–æ–≤—É—é –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é
    test_config = ConfigManagerConfig(
        config_dir="./test_configs",
        cache_ttl_seconds=60,
        auto_reload=False  # –û—Ç–∫–ª—é—á–∞–µ–º –¥–ª—è —Ç–µ—Å—Ç–æ–≤
    )
    
    manager = ProductionConfigManager(test_config)
    
    # –¢–µ—Å—Ç–∏—Ä—É–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
    stats = manager.get_stats()
    print(f"Manager stats: {stats}")
    
    # –¢–µ—Å—Ç–∏—Ä—É–µ–º –∑–∞–≥—Ä—É–∑–∫—É –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
    thresholds = manager.get_config('memory_thresholds', default={'test': 0.5})
    print(f"Memory thresholds: {thresholds}")
    
    # –¢–µ—Å—Ç–∏—Ä—É–µ–º –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è
    os.environ['MEMORY__TEST_CONFIG__PARAM1'] = '42'
    os.environ['MEMORY__TEST_CONFIG__NESTED__PARAM2'] = 'true'
    
    test_config = manager.get_config('test_config')
    print(f"Test config with env overrides: {test_config}")
    
    print("‚úÖ ProductionConfigManager test completed")
