
import os
import json
import yaml
from typing import Dict, Any, List, Optional
from pathlib import Path

class MemoryConfig:
    """–ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è —Å–∏—Å—Ç–µ–º—ã –ø–∞–º—è—Ç–∏"""
    
    def __init__(self, config_path: Optional[str] = None):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
        
        Args:
            config_path: –ü—É—Ç—å –∫ —Ñ–∞–π–ª—É –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ (YAML/JSON)
        """
        self.config_path = config_path or os.getenv('MEMORY_CONFIG_PATH')
        self._config_data = self._load_config()
        
    def _load_config(self) -> Dict[str, Any]:
        """–ó–∞–≥—Ä—É–∑–∏—Ç—å –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é –∏–∑ —Ñ–∞–π–ª–∞ –∏–ª–∏ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è"""
        config = {}
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –∏–∑ —Ñ–∞–π–ª–∞ –µ—Å–ª–∏ –µ—Å—Ç—å
        if self.config_path and Path(self.config_path).exists():
            config.update(self._load_from_file())
        
        # –ü–µ—Ä–µ–æ–ø—Ä–µ–¥–µ–ª—è–µ–º –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–º–∏ –æ–∫—Ä—É–∂–µ–Ω–∏—è
        config.update(self._load_from_env())
        
        return config
    
    def _load_from_file(self) -> Dict[str, Any]:
        """–ó–∞–≥—Ä—É–∑–∏—Ç—å –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é –∏–∑ —Ñ–∞–π–ª–∞"""
        try:
            with open(self.config_path, 'r', encoding='utf-8') as f:
                if self.config_path.endswith('.yaml') or self.config_path.endswith('.yml'):
                    return yaml.safe_load(f) or {}
                else:
                    return json.load(f)
        except Exception as e:
            print(f"‚ö†Ô∏è Failed to load config from {self.config_path}: {e}")
            return {}
    
    def _load_from_env(self) -> Dict[str, Any]:
        """–ó–∞–≥—Ä—É–∑–∏—Ç—å –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é –∏–∑ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è"""
        return {
            # –û–±—â–∏–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏
            'memory_type': os.getenv('MEMORY_TYPE', 'advanced'),
            'debug_mode': os.getenv('MEMORY_DEBUG', 'false').lower() == 'true',
            
            # Short-Term Memory
            'short_term': {
                'enabled': os.getenv('SHORT_TERM_ENABLED', 'true').lower() == 'true',
                'max_messages': int(os.getenv('SHORT_TERM_MAX_MESSAGES', '10')),
                'provider': os.getenv('SHORT_TERM_PROVIDER', 'langchain_buffer'),
                'ttl_seconds': int(os.getenv('SHORT_TERM_TTL', '3600')),
            },
            
            # Episodic Memory
            'episodic': {
                'enabled': os.getenv('EPISODIC_ENABLED', 'true').lower() == 'true',
                'auto_save_episodes': os.getenv('EPISODIC_AUTO_SAVE', 'true').lower() == 'true',
                'episode_min_messages': int(os.getenv('EPISODIC_MIN_MESSAGES', '5')),
                'episode_timeout_minutes': int(os.getenv('EPISODIC_TIMEOUT', '30')),
            },
            
            # Long-Term Memory
            'long_term': {
                'enabled': os.getenv('LONG_TERM_ENABLED', 'true').lower() == 'true',
                'provider': os.getenv('LONG_TERM_PROVIDER', 'chroma'),  # chroma, pinecone, weaviate, faiss
                'importance_threshold': float(os.getenv('LONG_TERM_IMPORTANCE_THRESHOLD', '0.6')),
                'max_storage_items': int(os.getenv('LONG_TERM_MAX_ITEMS', '10000')),
            },
            
            # Summary Memory
            'summary': {
                'enabled': os.getenv('SUMMARY_ENABLED', 'true').lower() == 'true',
                'auto_summarize': os.getenv('SUMMARY_AUTO', 'true').lower() == 'true',
                'trigger_message_count': int(os.getenv('SUMMARY_TRIGGER_COUNT', '50')),
                'max_summary_length': int(os.getenv('SUMMARY_MAX_LENGTH', '500')),
                'summarizer_model': os.getenv('SUMMARY_MODEL', 'gpt-4o-mini'),
            },
            
            # Vector Database
            'vector_db': {
                'provider': os.getenv('VECTOR_DB_PROVIDER', 'chroma'),
                'connection_string': os.getenv('VECTOR_DB_CONNECTION'),
                'collection_prefix': os.getenv('VECTOR_DB_COLLECTION_PREFIX', 'agatha_memory'),
                'persist_directory': os.getenv('VECTOR_DB_PERSIST_DIR', './vector_db'),
                'distance_metric': os.getenv('VECTOR_DB_DISTANCE', 'cosine'),
            },
            
            # Embeddings
            'embeddings': {
                'provider': os.getenv('EMBEDDINGS_PROVIDER', 'openai'),  # openai, huggingface, cohere
                'model': os.getenv('EMBEDDINGS_MODEL', 'text-embedding-3-small'),
                'api_key': os.getenv('EMBEDDINGS_API_KEY') or os.getenv('OPENAI_API_KEY'),
                'chunk_size': int(os.getenv('EMBEDDINGS_CHUNK_SIZE', '1000')),
                'chunk_overlap': int(os.getenv('EMBEDDINGS_CHUNK_OVERLAP', '200')),
            },
            
            # Search
            'search': {
                'hybrid_enabled': os.getenv('SEARCH_HYBRID_ENABLED', 'true').lower() == 'true',
                'semantic_weight': float(os.getenv('SEARCH_SEMANTIC_WEIGHT', '0.7')),
                'keyword_weight': float(os.getenv('SEARCH_KEYWORD_WEIGHT', '0.3')),
                'max_results': int(os.getenv('SEARCH_MAX_RESULTS', '5')),
                'similarity_threshold': float(os.getenv('SEARCH_SIMILARITY_THRESHOLD', '0.6')),
            },
            
            # Information Extraction
            'extraction': {
                'enabled': os.getenv('INFO_EXTRACTION_ENABLED', 'true').lower() == 'true',
                'extractors_config_path': os.getenv('EXTRACTORS_CONFIG_PATH'),
                'auto_extract_entities': os.getenv('AUTO_EXTRACT_ENTITIES', 'true').lower() == 'true',
                'extract_importance_threshold': float(os.getenv('EXTRACT_IMPORTANCE_THRESHOLD', '0.5')),
            }
        }
    
    def get(self, key_path: str, default: Any = None) -> Any:
        """
        –ü–æ–ª—É—á–∏—Ç—å –∑–Ω–∞—á–µ–Ω–∏–µ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ –ø–æ –ø—É—Ç–∏ (—á–µ—Ä–µ–∑ —Ç–æ—á–∫—É)
        
        Args:
            key_path: –ü—É—Ç—å –∫ –∫–ª—é—á—É, –Ω–∞–ø—Ä–∏–º–µ—Ä 'short_term.max_messages'
            default: –ó–Ω–∞—á–µ–Ω–∏–µ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
            
        Returns:
            –ó–Ω–∞—á–µ–Ω–∏–µ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
        """
        keys = key_path.split('.')
        value = self._config_data
        
        try:
            for key in keys:
                value = value[key]
            return value
        except (KeyError, TypeError):
            return default
    
    def update(self, key_path: str, value: Any) -> None:
        """
        –û–±–Ω–æ–≤–∏—Ç—å –∑–Ω–∞—á–µ–Ω–∏–µ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
        
        Args:
            key_path: –ü—É—Ç—å –∫ –∫–ª—é—á—É
            value: –ù–æ–≤–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ
        """
        keys = key_path.split('.')
        config_dict = self._config_data
        
        # –ù–∞–≤–∏–≥–∞—Ü–∏—è –¥–æ –ø—Ä–µ–¥–ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ –∫–ª—é—á–∞
        for key in keys[:-1]:
            if key not in config_dict:
                config_dict[key] = {}
            config_dict = config_dict[key]
        
        # –£—Å—Ç–∞–Ω–æ–≤–∫–∞ –∑–Ω–∞—á–µ–Ω–∏—è
        config_dict[keys[-1]] = value
    
    def is_enabled(self, component: str) -> bool:
        """–ü—Ä–æ–≤–µ—Ä–∏—Ç—å, –≤–∫–ª—é—á–µ–Ω –ª–∏ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç"""
        return self.get(f'{component}.enabled', False)
    
    def get_provider_config(self, component: str) -> Dict[str, Any]:
        """–ü–æ–ª—É—á–∏—Ç—å –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é –ø—Ä–æ–≤–∞–π–¥–µ—Ä–∞ –¥–ª—è –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–∞"""
        provider = self.get(f'{component}.provider')
        if not provider:
            return {}
        
        # –ë–∞–∑–æ–≤–∞—è –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è
        config = dict(self._config_data.get(component, {}))
        
        # –î–æ–±–∞–≤–ª—è–µ–º —Å–ø–µ—Ü–∏—Ñ–∏—á–Ω—ã–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –ø—Ä–æ–≤–∞–π–¥–µ—Ä–∞
        provider_config = self._config_data.get(f'{component}_providers', {}).get(provider, {})
        config.update(provider_config)
        
        return config
    
    def validate(self) -> List[str]:
        """
        –í–∞–ª–∏–¥–∞—Ü–∏—è –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
        
        Returns:
            –°–ø–∏—Å–æ–∫ –æ—à–∏–±–æ–∫ –≤–∞–ª–∏–¥–∞—Ü–∏–∏
        """
        errors = []
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–µ –ø–æ–ª—è
        required_fields = [
            'vector_db.provider',
            'embeddings.provider',
        ]
        
        for field in required_fields:
            if not self.get(field):
                errors.append(f"Required field '{field}' is missing")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º API –∫–ª—é—á–∏
        if self.get('embeddings.provider') == 'openai' and not self.get('embeddings.api_key'):
            errors.append("OpenAI API key is required for OpenAI embeddings")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –≤–µ–∫—Ç–æ—Ä–Ω—É—é –ë–î
        vector_provider = self.get('vector_db.provider')
        if vector_provider == 'pinecone' and not self.get('vector_db.connection_string'):
            errors.append("Pinecone connection string is required")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á–∏—Å–ª–æ–≤—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è
        numeric_checks = [
            ('short_term.max_messages', 1, 1000),
            ('search.max_results', 1, 100),
            ('summary.trigger_message_count', 1, 10000),
        ]
        
        for field, min_val, max_val in numeric_checks:
            value = self.get(field)
            if value is not None and not (min_val <= value <= max_val):
                errors.append(f"Field '{field}' value {value} is out of range [{min_val}, {max_val}]")
        
        return errors
    
    def to_dict(self) -> Dict[str, Any]:
        """–ü–æ–ª—É—á–∏—Ç—å –ø–æ–ª–Ω—É—é –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é –∫–∞–∫ —Å–ª–æ–≤–∞—Ä—å"""
        return self._config_data.copy()
    
    def save_to_file(self, file_path: str) -> None:
        """–°–æ—Ö—Ä–∞–Ω–∏—Ç—å –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é –≤ —Ñ–∞–π–ª"""
        try:
            with open(file_path, 'w', encoding='utf-8') as f:
                if file_path.endswith('.yaml') or file_path.endswith('.yml'):
                    yaml.dump(self._config_data, f, default_flow_style=False, allow_unicode=True)
                else:
                    json.dump(self._config_data, f, indent=2, ensure_ascii=False)
            print(f"‚úÖ Configuration saved to {file_path}")
        except Exception as e:
            print(f"‚ùå Failed to save configuration to {file_path}: {e}")


# –ì–ª–æ–±–∞–ª—å–Ω—ã–π —ç–∫–∑–µ–º–ø–ª—è—Ä –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
memory_config = MemoryConfig()

# –í–∞–ª–∏–¥–∞—Ü–∏—è –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ
validation_errors = memory_config.validate()
if validation_errors:
    print("‚ö†Ô∏è Memory configuration validation errors:")
    for error in validation_errors:
        print(f"   - {error}")
else:
    print("‚úÖ Memory configuration loaded successfully")


# –ü—Ä–∏–º–µ—Ä —Ñ–∞–π–ª–∞ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ (–º–æ–∂–µ—Ç –±—ã—Ç—å —Å–æ–∑–¥–∞–Ω –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏)
EXAMPLE_CONFIG = """
# –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è —Å–∏—Å—Ç–µ–º—ã –ø–∞–º—è—Ç–∏ Agatha AI
memory_type: advanced
debug_mode: false

short_term:
  enabled: true
  max_messages: 10
  provider: langchain_buffer
  ttl_seconds: 3600

episodic:
  enabled: true
  auto_save_episodes: true
  episode_min_messages: 5
  episode_timeout_minutes: 30

long_term:
  enabled: true
  provider: chroma  # chroma, pinecone, weaviate, faiss
  importance_threshold: 0.6
  max_storage_items: 10000

summary:
  enabled: true
  auto_summarize: true
  trigger_message_count: 50
  max_summary_length: 500
  summarizer_model: gpt-4o-mini

vector_db:
  provider: chroma
  collection_prefix: agatha_memory
  persist_directory: ./vector_db
  distance_metric: cosine

embeddings:
  provider: openai  # openai, huggingface, cohere
  model: text-embedding-3-small
  chunk_size: 1000
  chunk_overlap: 200

search:
  hybrid_enabled: true
  semantic_weight: 0.7
  keyword_weight: 0.3
  max_results: 5
  similarity_threshold: 0.6

extraction:
  enabled: true
  auto_extract_entities: true
  extract_importance_threshold: 0.5
  
  # –ö–æ–Ω—Ñ–∏–≥—É—Ä–∏—Ä—É–µ–º—ã–µ —ç–∫—Å—Ç—Ä–∞–∫—Ç–æ—Ä—ã
  extractors:
    personal_info:
      patterns:
        name: 
          - "–∑–æ–≤—É—Ç\\s+(\\w+)"
          - "–º–µ–Ω—è\\s+–∑–æ–≤—É—Ç\\s+(\\w+)"
          - "–∏–º—è\\s+(\\w+)"
        age:
          - "–º–Ω–µ\\s+(\\d+)\\s*(?:–ª–µ—Ç|–≥–æ–¥–∞|–≥–æ–¥)"
          - "–≤–æ–∑—Ä–∞—Å—Ç\\s+(\\d+)"
        profession:
          - "—Ä–∞–±–æ—Ç–∞—é\\s+(\\w+)"
          - "–ø—Ä–æ—Ñ–µ—Å—Å–∏—è\\s+(\\w+)"
      importance_weight: 1.0
    
    interests:
      keywords:
        - "–ª—é–±–ª—é"
        - "–Ω—Ä–∞–≤–∏—Ç—Å—è" 
        - "—É–≤–ª–µ–∫–∞—é—Å—å"
        - "—Ö–æ–±–±–∏"
      importance_weight: 0.8
    
    locations:
      patterns:
        city:
          - "–∂–∏–≤—É\\s+–≤\\s+(\\w+)"
          - "–∏–∑\\s+(\\w+)"
          - "–≥–æ—Ä–æ–¥\\s+(\\w+)"
      importance_weight: 0.7
"""

def create_example_config(file_path: str = './memory_config.yaml') -> None:
    """–°–æ–∑–¥–∞—Ç—å –ø—Ä–∏–º–µ—Ä —Ñ–∞–π–ª–∞ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏"""
    try:
        with open(file_path, 'w', encoding='utf-8') as f:
            f.write(EXAMPLE_CONFIG)
        print(f"‚úÖ Example configuration created at {file_path}")
    except Exception as e:
        print(f"‚ùå Failed to create example config: {e}")


if __name__ == "__main__":
    # –¢–µ—Å—Ç –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
    config = MemoryConfig()
    
    print("üìã Current Memory Configuration:")
    print(f"  Memory Type: {config.get('memory_type')}")
    print(f"  Short-Term Max Messages: {config.get('short_term.max_messages')}")
    print(f"  Vector DB Provider: {config.get('vector_db.provider')}")
    print(f"  Embeddings Provider: {config.get('embeddings.provider')}")
    print(f"  Hybrid Search: {config.get('search.hybrid_enabled')}")
    
    # –°–æ–∑–¥–∞–µ–º –ø—Ä–∏–º–µ—Ä –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
    create_example_config()
