import os
import re
from datetime import datetime
from typing import Dict, List, Any, Optional, TypedDict
from langgraph.graph import StateGraph
from langchain_openai import ChatOpenAI
from langchain_core.messages import HumanMessage

from ..memory.hybrid_memory import HybridMemory
from ..config.settings import settings
from ..utils.prompt_loader import PromptLoader
from ..utils.time_utils import TimeUtils
from ..utils.message_controller import MessageController
from ..utils.behavioral_analyzer import BehavioralAnalyzer
from ..utils.prompt_composer import PromptComposer
from ..utils.message_splitter import message_splitter
from ..utils.question_controller import question_controller
from ..utils.question_filter import question_filter
from ..memory.memory_adapter import MemoryAdapter
from ..graph.nodes.compose_prompt import ComposePromptNode

QUIET_MODE = os.getenv('AGATHA_QUIET', 'false').lower() == 'true'

def log_info(message: str):
    if not QUIET_MODE:
        print(message)

class PipelineState(TypedDict):
    user_id: str
    messages: List[Dict[str, Any]]
    meta_time: Optional[datetime]
    normalized_input: str
    memory_context: str
    day_prompt: str
    behavior_prompt: str
    final_prompt: str
    llm_response: str
    processed_response: Dict[str, Any]
    current_strategy: str
    behavioral_analysis: Dict[str, Any]
    strategy_confidence: float
    day_number: int

    dynamic_formatted_prompt: Optional[List[Any]]
    dynamic_system_used: Optional[bool]
    dynamic_final_prompt: Optional[str]
    question_count: int
    processing_start: datetime
    # –ü–æ–ª—è –¥–ª—è –∫–æ–Ω—Ç—Ä–æ–ª—è –≤–æ–ø—Ä–æ—Å–æ–≤
    may_ask_question: Optional[bool]
    has_question_after_filter: Optional[bool]

class AgathaPipeline:
    def __init__(self):
        self.prompt_loader = PromptLoader()
        self.time_utils = TimeUtils()
        self.message_controllers = {}
        self.behavioral_analyzer = BehavioralAnalyzer()
        self.prompt_composer = PromptComposer()
        self.memories = {}
        self.compose_prompt_node = ComposePromptNode()

        api_key = os.getenv('OPENAI_API_KEY') or settings.OPENAI_API_KEY
        if not api_key:
            raise ValueError("OPENAI_API_KEY required")

        log_info(f"Using OpenAI API key: {api_key[:20]}...")
        self.llm = ChatOpenAI(
            api_key=api_key,
            model=settings.LLM_MODEL,
            temperature=0.8
        )

        self.graph = self._build_graph()

    def _get_memory(self, user_id: str):
        if user_id not in self.memories:
            try:
                from ..memory.unified_memory import UnifiedMemoryManager
                from ..memory.memory_adapter import MemoryAdapter
                
                # –ü–æ–ª—É—á–∞–µ–º –≥–ª–æ–±–∞–ª—å–Ω—ã–π —ç–∫–∑–µ–º–ø–ª—è—Ä UnifiedMemoryManager
                from ..memory.memory_manager import get_unified_memory
                unified_memory = get_unified_memory(user_id)
                if not unified_memory:
                    raise Exception(f"Failed to get unified memory for {user_id}")
                
                # –û–±–æ—Ä–∞—á–∏–≤–∞–µ–º –≤ MemoryAdapter –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏
                memory_adapter = MemoryAdapter(unified_memory)
                
                self.memories[user_id] = {
                    'unified': unified_memory,
                    'adapter': memory_adapter,
                    'type': 'unified'
                }
                log_info(f"‚úÖ Initialized UnifiedMemoryManager for {user_id}")
            except Exception as e:
                log_info(f"‚ö†Ô∏è Failed to initialize UnifiedMemoryManager: {e}, falling back to old system")
                # Fallback –∫ —Å—Ç–∞—Ä–æ–π —Å–∏—Å—Ç–µ–º–µ
                try:
                    from ..memory.memory_levels import MemoryLevelsManager
                    self.memories[user_id] = MemoryLevelsManager(user_id)
                    log_info(f"‚úÖ Initialized MemoryLevelsManager as fallback for {user_id}")
                except Exception as e2:
                    from ..memory.hybrid_memory import HybridMemory
                    self.memories[user_id] = HybridMemory(user_id)
                    log_info(f"‚úÖ Initialized HybridMemory as final fallback for {user_id}")
        
        return self.memories[user_id]

    def _build_graph(self):
        workflow = StateGraph(PipelineState)
        workflow.add_node("ingest_input", self._ingest_input)
        workflow.add_node("short_memory", self._short_memory)
        workflow.add_node("day_policy", self._day_policy)
        workflow.add_node("behavior_policy", self._behavior_policy)
        workflow.add_node("compose_prompt", self._compose_prompt)
        workflow.add_node("llm_call", self._llm_call)
        workflow.add_node("postprocess", self._postprocess)
        workflow.add_node("persist", self._persist)
        
        # Add edges - –ø—Ä–∞–≤–∏–ª—å–Ω—ã–π API –¥–ª—è 0.2.50
        workflow.add_edge("ingest_input", "short_memory")
        workflow.add_edge("short_memory", "day_policy")
        workflow.add_edge("day_policy", "behavior_policy")
        workflow.add_edge("behavior_policy", "compose_prompt")
        workflow.add_edge("compose_prompt", "llm_call")
        workflow.add_edge("llm_call", "postprocess")
        workflow.add_edge("postprocess", "persist")

        workflow.set_entry_point("ingest_input")
        workflow.set_finish_point("persist")

        return workflow.compile()

    def _ensure_stage_data(self, state: PipelineState) -> None:
        """–£–±–µ–¥–∏—Ç—å—Å—è, —á—Ç–æ stage –¥–∞–Ω–Ω—ã–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ state"""
        if "stage_number" not in state:
            message_count = len(state.get("messages", []))
            # –ü—Ä–∞–≤–∏–ª—å–Ω–∞—è –ª–æ–≥–∏–∫–∞ —ç—Ç–∞–ø–æ–≤ —Å–æ–≥–ª–∞—Å–Ω–æ –¢–ó:
            # –≠—Ç–∞–ø 1: 1-5 —Å–æ–æ–±—â–µ–Ω–∏–π, –≠—Ç–∞–ø 2: 5-15 —Å–æ–æ–±—â–µ–Ω–∏–π, –≠—Ç–∞–ø 3: 15+ —Å–æ–æ–±—â–µ–Ω–∏–π
            if message_count <= 5:
                stage_number = 1
            elif message_count <= 15:
                stage_number = 2
            else:
                stage_number = 3
            state["stage_number"] = stage_number
            state["stage_prompt"] = self.prompt_loader.get_stage_prompt(stage_number)
            log_info(f"Ensured stage {stage_number} data in state")

    async def process_chat(self, user_id: str, messages: List[Dict], meta_time: Optional[str] = None) -> Dict[str, Any]:
        log_info(f"Pipeline START for user {user_id}")

        state: PipelineState = {
            "user_id": user_id,
            "messages": messages,
            "meta_time": None,
            "normalized_input": "",
            "memory_context": "",
            "day_prompt": "",
            "stage_prompt": "",
            "behavior_prompt": "",
            "final_prompt": "",
            "llm_response": "",
            "processed_response": {},
            "current_strategy": "caring",
            "behavioral_analysis": {},
            "strategy_confidence": 0.0,
            "day_number": 1,
            "stage_number": 1,
            "question_count": 0,
            "processing_start": datetime.utcnow()
        }
        
        if meta_time:
            try:
                # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Å–ª—É—á–∞–π –∫–æ–≥–¥–∞ meta_time - —Å–ª–æ–≤–∞—Ä—å –∏–ª–∏ —Å—Ç—Ä–æ–∫–∞
                if isinstance(meta_time, dict):
                    # –ï—Å–ª–∏ —Å–ª–æ–≤–∞—Ä—å, –∏—Å–ø–æ–ª—å–∑—É–µ–º —Ç–µ–∫—É—â–µ–µ –≤—Ä–µ–º—è
                    state["meta_time"] = datetime.utcnow()
                elif isinstance(meta_time, str):
                    # –ï—Å–ª–∏ —Å—Ç—Ä–æ–∫–∞, –ø–∞—Ä—Å–∏–º ISO —Ñ–æ—Ä–º–∞—Ç
                    state["meta_time"] = datetime.fromisoformat(meta_time.replace('Z', '+00:00'))
                else:
                    state["meta_time"] = datetime.utcnow()
            except Exception as e:
                log_info(f"Warning: Failed to parse meta_time {meta_time}: {e}")
                state["meta_time"] = datetime.utcnow()
        else:
            state["meta_time"] = datetime.utcnow()
        
        log_info(f"üìù Initial state: {state}")

        try:
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º –ê–°–ò–ù–•–†–û–ù–ù–´–ô ainvoke()
            result = await self.graph.ainvoke(state)
            log_info(f"‚úÖ LangGraph Pipeline COMPLETED: {result}")
            
            # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –ø–æ–ª–Ω—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç —Å behavioral analysis
            return {
                "parts": result["processed_response"].get("parts", []),
                "has_question": result["processed_response"].get("has_question", False),
                "delays_ms": result["processed_response"].get("delays_ms", []),
                "behavioral_analysis": result.get("behavioral_analysis", {}),
                "current_strategy": result.get("current_strategy", "unknown"),
                "stage_number": result.get("stage_number", 1),
                "day_number": result.get("day_number", 1)
            }
        except Exception as e:
            log_info(f"‚ùå LangGraph Pipeline FAILED: {e}")
            raise e
    
    async def _ingest_input(self, state: PipelineState) -> PipelineState:
        """Node 1: Process input and normalize - –ê–°–ò–ù–•–†–û–ù–ù–´–ô"""
        log_info("üöÄ NODE: _ingest_input ‚úÖ STARTED")
        if not state["messages"]:
            state["normalized_input"] = ""
            return state
        
        # Get last user message
        user_messages = [msg for msg in state["messages"] if msg.get('role') == 'user']
        if user_messages:
            last_message = user_messages[-1]
            state["normalized_input"] = last_message.get('content', '').strip()
        
        # Set day number and stage
        # –í—ã—á–∏—Å–ª—è–µ–º –Ω–æ–º–µ—Ä –¥–Ω—è –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø–µ—Ä–≤–æ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
        user_id = state["user_id"]
        memory = self._get_memory(user_id)
        if hasattr(memory, 'get_user_stats'):
            stats = memory.get_user_stats()
            state["day_number"] = stats.get('days_since_start', 1)
        else:
            state["day_number"] = 1

        # Determine stage based on message count
        message_count = len(state.get("messages", []))
        # –ü—Ä–∞–≤–∏–ª—å–Ω–∞—è –ª–æ–≥–∏–∫–∞ —ç—Ç–∞–ø–æ–≤ —Å–æ–≥–ª–∞—Å–Ω–æ –¢–ó:
        # –≠—Ç–∞–ø 1: 1-5 —Å–æ–æ–±—â–µ–Ω–∏–π, –≠—Ç–∞–ø 2: 5-15 —Å–æ–æ–±—â–µ–Ω–∏–π, –≠—Ç–∞–ø 3: 15+ —Å–æ–æ–±—â–µ–Ω–∏–π
        if message_count <= 5:
            stage_number = 1
        elif message_count <= 15:
            stage_number = 2
        else:
            stage_number = 3
        state["stage_number"] = stage_number
        stage_prompt = self.prompt_loader.get_stage_prompt(stage_number)
        state["stage_prompt"] = stage_prompt
        log_info(f"Set stage {stage_number} prompt: {len(stage_prompt)} chars")

        return state
    
    async def _short_memory(self, state: PipelineState) -> PipelineState:
        log_info("üß† NODE: _short_memory ‚úÖ STARTED")
        user_id = state["user_id"]

        # –£–±–µ–¥–∏–º—Å—è, —á—Ç–æ —ç—Ç–∞–ø —Å–æ—Ö—Ä–∞–Ω–µ–Ω
        if "stage_number" not in state:
            message_count = len(state.get("messages", []))
            # –ü—Ä–∞–≤–∏–ª—å–Ω–∞—è –ª–æ–≥–∏–∫–∞ —ç—Ç–∞–ø–æ–≤ —Å–æ–≥–ª–∞—Å–Ω–æ –¢–ó:
            # –≠—Ç–∞–ø 1: 1-5 —Å–æ–æ–±—â–µ–Ω–∏–π, –≠—Ç–∞–ø 2: 5-15 —Å–æ–æ–±—â–µ–Ω–∏–π, –≠—Ç–∞–ø 3: 15+ —Å–æ–æ–±—â–µ–Ω–∏–π
            if message_count <= 5:
                stage_number = 1
            elif message_count <= 15:
                stage_number = 2
            else:
                stage_number = 3
            state["stage_number"] = stage_number
            state["stage_prompt"] = self.prompt_loader.get_stage_prompt(stage_number)

        memory = self._get_memory(user_id)
        

        if isinstance(memory, dict) and memory.get('type') == 'unified':
            log_info(" –ò—Å–ø–æ–ª—å–∑—É–µ–º –ù–û–í–£–Æ –ê–†–•–ò–¢–ï–ö–¢–£–†–£ (UnifiedMemoryManager)")
            unified_memory = memory['unified']
            memory_adapter = memory['adapter']
            
            # –î–æ–±–∞–≤–ª—è–µ–º —Å–æ–æ–±—â–µ–Ω–∏–µ –≤ —É–Ω–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω—É—é —Å–∏—Å—Ç–µ–º—É
            if state["normalized_input"]:
                result = memory_adapter.add_message_to_unified(
                    role="user",
                    content=state["normalized_input"],
                    metadata={
                        'timestamp': (state["meta_time"] or datetime.utcnow()).isoformat(),
                        'day_number': state["day_number"],
                        'user_id': user_id
                    },
                    user_id=user_id
                )
                log_info(f"‚úÖ –°–æ–æ–±—â–µ–Ω–∏–µ –¥–æ–±–∞–≤–ª–µ–Ω–æ –≤ —É–Ω–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω—É—é –ø–∞–º—è—Ç—å: {result}")
            
            # –ü–µ—Ä–µ–¥–∞–µ–º memory_adapter –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏
            state["memory_manager"] = memory_adapter
        else:
            log_info("‚ö†Ô∏è –ò—Å–ø–æ–ª—å–∑—É–µ–º –°–¢–ê–†–£–Æ –ê–†–•–ò–¢–ï–ö–¢–£–†–£ (fallback)")
            # –î–æ–±–∞–≤–ª—è–µ–º memory_manager –≤ state –¥–ª—è ComposePromptNode
            state["memory_manager"] = memory

            if state["normalized_input"]:
                from ..memory.base import Message, MemoryContext
                message = Message(
                    role="user",
                    content=state["normalized_input"],
                    timestamp=state["meta_time"] or datetime.utcnow()
                )
                context = MemoryContext(
                    user_id=user_id,
                    day_number=state["day_number"]
                )
                memory.add_message(message, context)

        
        try:
            if isinstance(memory, dict) and memory.get('type') == 'unified':
                memory_adapter = memory['adapter']
            else:
                memory_adapter = MemoryAdapter(memory)
            memory_data = memory_adapter.get_for_prompt(
                user_id=state["user_id"],
                query=state["normalized_input"]
            )
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –¥–∞–Ω–Ω—ã–µ –ø–∞–º—è—Ç–∏ –≤ —Å–æ—Å—Ç–æ—è–Ω–∏–∏
            state["memory"] = memory_data
            
            # –§–æ—Ä–º–∏—Ä—É–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç –¥–ª—è –æ–±—Ä–∞—Ç–Ω–æ–π —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏
            memory_contexts = []
            
            # –î–æ–±–∞–≤–ª—è–µ–º –∫–æ—Ä–æ—Ç–∫—É—é —Å–≤–æ–¥–∫—É
            if memory_data.get("short_memory_summary") and memory_data["short_memory_summary"] != "‚Äî":
                memory_contexts.append(f"–ù–µ–¥–∞–≤–Ω–∏–π —Ä–∞–∑–≥–æ–≤–æ—Ä:\n{memory_data['short_memory_summary']}")
            
            # –î–æ–±–∞–≤–ª—è–µ–º –¥–æ–ª–≥–æ—Å—Ä–æ—á–Ω—ã–µ —Ñ–∞–∫—Ç—ã
            if memory_data.get("long_memory_facts") and memory_data["long_memory_facts"] != "‚Äî":
                memory_contexts.append(f"–í–∞–∂–Ω—ã–µ —Ñ–∞–∫—Ç—ã:\n{memory_data['long_memory_facts']}")
            
            # –î–æ–±–∞–≤–ª—è–µ–º —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–π –∫–æ–Ω—Ç–µ–∫—Å—Ç
            if memory_data.get("semantic_context") and memory_data["semantic_context"] != "‚Äî":
                memory_contexts.append(f"–†–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç:\n{memory_data['semantic_context']}")
            
            # –û–±—ä–µ–¥–∏–Ω—è–µ–º –≤—Å–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç—ã
            if memory_contexts:
                state["memory_context"] = "\n\n".join(memory_contexts)
                log_info(f"‚úÖ Memory context assembled: {len(state['memory_context'])} chars")
            else:
                state["memory_context"] = "–ù–∞—á–∏–Ω–∞–µ–º –Ω–æ–≤—ã–π —Ä–∞–∑–≥–æ–≤–æ—Ä"
                
        except Exception as e:
            log_info(f"Warning: Could not get memory context via adapter: {e}")
            state["memory"] = {"short_memory_summary": "‚Äî", "long_memory_facts": "‚Äî", "semantic_context": "‚Äî"}
            state["memory_context"] = "–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –ø–∞–º—è—Ç–∏"

        return state
    
    async def _day_policy(self, state: PipelineState) -> PipelineState:
        """Node 3: Apply daily scenario policy - –ê–°–ò–ù–•–†–û–ù–ù–´–ô"""
        day_number = state["day_number"]
        
        # –£–±–µ–¥–∏–º—Å—è, —á—Ç–æ —ç—Ç–∞–ø —Å–æ—Ö—Ä–∞–Ω–µ–Ω
        if "stage_number" not in state:
            message_count = len(state.get("messages", []))
            # –ü—Ä–∞–≤–∏–ª—å–Ω–∞—è –ª–æ–≥–∏–∫–∞ —ç—Ç–∞–ø–æ–≤ —Å–æ–≥–ª–∞—Å–Ω–æ –¢–ó:
            # –≠—Ç–∞–ø 1: 1-5 —Å–æ–æ–±—â–µ–Ω–∏–π, –≠—Ç–∞–ø 2: 5-15 —Å–æ–æ–±—â–µ–Ω–∏–π, –≠—Ç–∞–ø 3: 15+ —Å–æ–æ–±—â–µ–Ω–∏–π
            if message_count <= 5:
                stage_number = 1
            elif message_count <= 15:
                stage_number = 2
            else:
                stage_number = 3
            state["stage_number"] = stage_number
            state["stage_prompt"] = self.prompt_loader.get_stage_prompt(stage_number)

        # –î–æ–±–∞–≤–ª—è–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç –≤—Ä–µ–º–µ–Ω–∏ –∏ –∏—Å—Ç–æ—Ä–∏–∏
        user_id = state["user_id"]
        memory = self._get_memory(user_id)

        try:
            # –ü–æ–ª—É—á–∞–µ–º –ø—Ä–æ—Ñ–∏–ª—å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –¥–ª—è –∞–¥–∞–ø—Ç–∞—Ü–∏–∏
            profile = memory.get_user_profile()
            insights = memory.get_conversation_insights()

            # –û–±–æ–≥–∞—â–∞–µ–º –ø—Ä–æ–º–ø—Ç –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º
            meta_time = state["meta_time"] or datetime.utcnow()
            if isinstance(meta_time, str):
                try:
                    meta_time = datetime.fromisoformat(meta_time.replace('Z', '+00:00'))
                except:
                    meta_time = datetime.utcnow()
            time_context = self.time_utils.get_time_context(meta_time)

            enhanced_prompt = f"""
{state["stage_prompt"]}

–ö–û–ù–¢–ï–ö–°–¢ –û–¢–ù–û–®–ï–ù–ò–ô:
- –°—Ç–∞–¥–∏—è –æ—Ç–Ω–æ—à–µ–Ω–∏–π: {insights.get('relationship_stage', 'introduction')}
- –£—Ä–æ–≤–µ–Ω—å –ø–µ—Ä—Å–æ–Ω–∞–ª–∏–∑–∞—Ü–∏–∏: {insights.get('personalization_level', 0):.1f}/1.0
- –ù–∞—Å—Ç—Ä–æ–µ–Ω–∏–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è: {profile.get('recent_mood', 'neutral')}
- –õ—é–±–∏–º—ã–µ —Ç–µ–º—ã: {', '.join([t[0] for t in profile.get('favorite_topics', [])[:3]])}

–í–†–ï–ú–ï–ù–ù–û–ô –ö–û–ù–¢–ï–ö–°–¢:
{time_context}

–ü–ê–ú–Ø–¢–¨ –ü–û–õ–¨–ó–û–í–ê–¢–ï–õ–Ø:
                {state["memory_context"]}
                """.strip()

            state["day_prompt"] = enhanced_prompt

        except Exception as e:
            log_info(f"Warning: Could not enhance day prompt: {e}")
        
        return state
    
    async def _behavior_policy(self, state: PipelineState) -> PipelineState:
        """Node 4: Behavioral Adaptation - –ê–°–ò–ù–•–†–û–ù–ù–´–ô"""
        log_info("üé≠ NODE: _behavior_policy ‚úÖ STARTED")
        user_id = state["user_id"]
        
        # –ü–æ–ª—É—á–∞–µ–º –ø—Ä–æ—Ñ–∏–ª—å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –∏ –∫–æ–Ω—Ç–µ–∫—Å—Ç
        memory = self._get_memory(user_id)
        user_profile = {}
        conversation_context = {}

        try:
            user_profile = memory.get_user_profile()
            conversation_context = memory.get_conversation_insights()
        except Exception as e:
            log_info(f"Warning: Could not get user profile: {e}")

        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –ø–æ–≤–µ–¥–µ–Ω–∏–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
        log_info(f"üé≠ Starting Behavioral Analysis for {user_id}...")
        try:
            behavioral_analysis = self.behavioral_analyzer.analyze_user_behavior(
                messages=state["messages"],
                user_profile=user_profile,
                conversation_context=conversation_context
            )

            # –í—ã–±–∏—Ä–∞–µ–º —Å—Ç—Ä–∞—Ç–µ–≥–∏—é –Ω–∞ –æ—Å–Ω–æ–≤–µ –∞–Ω–∞–ª–∏–∑–∞
            recommended_strategy = behavioral_analysis['recommended_strategy']
            strategy_confidence = behavioral_analysis['strategy_confidence']

            # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –∞–Ω–∞–ª–∏–∑–∞ –≤ —Å–æ—Å—Ç–æ—è–Ω–∏–∏
            state["current_strategy"] = recommended_strategy
            state["behavioral_analysis"] = behavioral_analysis
            state["strategy_confidence"] = strategy_confidence

            # –õ–æ–≥–∏—Ä—É–µ–º –≤—ã–±–æ—Ä —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏
            log_info(f"üé≠ Behavioral Analysis for {user_id}: ‚úÖ SUCCESS")
            log_info(f"   Emotion: {behavioral_analysis['dominant_emotion']} (intensity: {behavioral_analysis['emotional_intensity']:.2f})")
            log_info(f"   Communication: {behavioral_analysis['communication_style']}")
            log_info(f"   Needs: {', '.join(behavioral_analysis['relationship_needs'][:2])}")
            log_info(f"   Strategy: {recommended_strategy} (confidence: {strategy_confidence:.2f})")

        except Exception as e:
            log_info(f"üé≠ Behavioral Analysis for {user_id}: ‚ùå ERROR - {e}")
            # Fallback –∫ –¥–µ—Ñ–æ–ª—Ç–Ω—ã–º –∑–Ω–∞—á–µ–Ω–∏—è–º
            state["current_strategy"] = "caring"
            state["behavioral_analysis"] = {}
            state["strategy_confidence"] = 0.0
        
        try:
            log_info(f"üé≠ NODE: _behavior_policy ‚úÖ COMPLETED -> –ø–µ—Ä–µ—Ö–æ–¥–∏–º –∫ compose_prompt")
            # –í—ã–≤–æ–¥–∏–º –ª–æ–≥ –≤ –∫–æ–Ω—Å–æ–ª—å
            print(f"üé≠ NODE: _behavior_policy ‚úÖ COMPLETED -> –ø–µ—Ä–µ—Ö–æ–¥–∏–º –∫ compose_prompt")
            return state
        except Exception as e:
            log_info(f"üé≠ NODE: _behavior_policy ‚ùå –ö–†–ò–¢–ò–ß–ï–°–ö–ê–Ø –û–®–ò–ë–ö–ê –ø—Ä–∏ –∑–∞–≤–µ—Ä—à–µ–Ω–∏–∏: {e}")
            print(f"üé≠ NODE: _behavior_policy ‚ùå –ö–†–ò–¢–ò–ß–ï–°–ö–ê–Ø –û–®–ò–ë–ö–ê –ø—Ä–∏ –∑–∞–≤–µ—Ä—à–µ–Ω–∏–∏: {e}")
            import traceback
            log_info(f"üé≠ NODE: _behavior_policy ‚ùå TRACEBACK: {traceback.format_exc()}")
            print(f"üé≠ NODE: _behavior_policy ‚ùå TRACEBACK: {traceback.format_exc()}")
            raise e
    
    async def _compose_prompt(self, state: PipelineState) -> PipelineState:
        """Node 5: Prompt Composition —Å –Ω–æ–≤—ã–º —Å–∏—Å—Ç–µ–º–Ω—ã–º –ø—Ä–æ–º–ø—Ç–æ–º - –ê–°–ò–ù–•–†–û–ù–ù–´–ô"""
        log_info(f"üéØ NODE: _compose_prompt ‚úÖ STARTED (user: {state.get('user_id', 'unknown')})")
        print(f"üéØ NODE: _compose_prompt ‚úÖ STARTED (user: {state.get('user_id', 'unknown')})")
        log_info(f"üéØ NODE: _compose_prompt - —Å–æ—Å—Ç–æ—è–Ω–∏–µ —Å–æ–¥–µ—Ä–∂–∏—Ç memory: {bool(state.get('memory'))}")
        print(f"üéØ NODE: _compose_prompt - —Å–æ—Å—Ç–æ—è–Ω–∏–µ —Å–æ–¥–µ—Ä–∂–∏—Ç memory: {bool(state.get('memory'))}")
        log_info(f"üéØ NODE: _compose_prompt - —Å–æ—Å—Ç–æ—è–Ω–∏–µ —Å–æ–¥–µ—Ä–∂–∏—Ç memory_context: {bool(state.get('memory_context'))}")
        print(f"üéØ NODE: _compose_prompt - —Å–æ—Å—Ç–æ—è–Ω–∏–µ —Å–æ–¥–µ—Ä–∂–∏—Ç memory_context: {len(state.get('memory_context', ''))} —Å–∏–º–≤–æ–ª–æ–≤")
        try:
            log_info(f"üîç DEBUG: –í—ã–∑—ã–≤–∞–µ–º ComposePromptNode...")
            
            # –î–æ–±–∞–≤–ª—è–µ–º memory_manager –≤ —Å–æ—Å—Ç–æ—è–Ω–∏–µ
            user_id = state.get("user_id", "unknown")
            if user_id in self.memories:
                memory_obj = self.memories[user_id]
                # –ï—Å–ª–∏ —ç—Ç–æ –Ω–æ–≤–∞—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ (—Å–ª–æ–≤–∞—Ä—å), –±–µ—Ä–µ–º adapter –∏ unified_memory
                if isinstance(memory_obj, dict) and 'adapter' in memory_obj:
                    state["memory_manager"] = memory_obj['adapter']
                    state["unified_memory"] = memory_obj['unified']  # –î–æ–±–∞–≤–ª—è–µ–º unified_memory –¥–ª—è –¥–æ—Å—Ç—É–ø–∞ –∫ get_last_activity_time
                    log_info(f"‚úÖ –î–æ–±–∞–≤–∏–ª–∏ MemoryAdapter –∏ UnifiedMemory –≤ —Å–æ—Å—Ç–æ—è–Ω–∏–µ –¥–ª—è {user_id}")
                    print(f"‚úÖ –î–æ–±–∞–≤–∏–ª–∏ MemoryAdapter –∏ UnifiedMemory –≤ —Å–æ—Å—Ç–æ—è–Ω–∏–µ –¥–ª—è {user_id}")
                else:
                    # –°—Ç–∞—Ä–∞—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞
                    state["memory_manager"] = memory_obj
                    log_info(f"‚úÖ –î–æ–±–∞–≤–∏–ª–∏ legacy memory_manager –≤ —Å–æ—Å—Ç–æ—è–Ω–∏–µ –¥–ª—è {user_id}")
                    print(f"‚úÖ –î–æ–±–∞–≤–∏–ª–∏ legacy memory_manager –≤ —Å–æ—Å—Ç–æ—è–Ω–∏–µ –¥–ª—è {user_id}")
            
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º ComposePromptNode
            updated_state = self.compose_prompt_node.compose_prompt(state)
            
            log_info(f"üîç DEBUG: ComposePromptNode –≤–µ—Ä–Ω—É–ª: {list(updated_state.keys()) if updated_state else 'None'}")
            log_info(f"üîç DEBUG: system_prompt_used –≤ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–µ: {updated_state.get('system_prompt_used') if updated_state else 'N/A'}")
            
            # –û–±–Ω–æ–≤–ª—è–µ–º —Å–æ—Å—Ç–æ—è–Ω–∏–µ pipeline
            if updated_state and updated_state.get("system_prompt_used"):
                state.update(updated_state)
                
                # –°–æ—Ö—Ä–∞–Ω—è–µ–º –¥–∞–Ω–Ω—ã–µ –≤ –Ω–∞–¥–µ–∂–Ω–æ–º –º–µ—Å—Ç–µ
                state["dynamic_formatted_prompt"] = updated_state.get("formatted_prompt")
                state["dynamic_system_used"] = True
                state["dynamic_final_prompt"] = updated_state.get("final_prompt")
                
                log_info(f"‚úÖ –ù–æ–≤—ã–π —Å–∏—Å—Ç–µ–º–Ω—ã–π –ø—Ä–æ–º–ø—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω")
                log_info(f"üìù Prompt info: {self.compose_prompt_node.get_prompt_info()}")
                log_info(f"üîç DEBUG: formatted_prompt –ø–æ—Å–ª–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è: {state.get('formatted_prompt') is not None}")
                log_info(f"üîç DEBUG: system_prompt_used –ø–æ—Å–ª–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è: {state.get('system_prompt_used')}")
                log_info(f"üîß DEBUG: –°–æ—Ö—Ä–∞–Ω–∏–ª–∏ –≤ dynamic_formatted_prompt: {state.get('dynamic_formatted_prompt') is not None}")
                log_info(f"üîß DEBUG: –°–æ—Ö—Ä–∞–Ω–∏–ª–∏ dynamic_system_used: {state.get('dynamic_system_used')}")
            else:
                log_info(f"‚ö†Ô∏è Fallback –∫ —Å—Ç–∞—Ä–æ–º—É —Å–ø–æ—Å–æ–±—É —Å–æ—Å—Ç–∞–≤–ª–µ–Ω–∏—è –ø—Ä–æ–º–ø—Ç–∞ (system_prompt_used={updated_state.get('system_prompt_used') if updated_state else 'None'})")
                # Fallback –∫ —Å—Ç–∞—Ä–æ–º—É —Å–ø–æ—Å–æ–±—É
                state = await self._compose_prompt_fallback(state)
            
        except Exception as e:
            log_info(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ—Å—Ç–∞–≤–ª–µ–Ω–∏—è –ø—Ä–æ–º–ø—Ç–∞: {e}")
            import traceback
            log_info(f"‚ùå Traceback: {traceback.format_exc()}")
            # Fallback –∫ —Å—Ç–∞—Ä–æ–º—É —Å–ø–æ—Å–æ–±—É
            state = await self._compose_prompt_fallback(state)
        
        log_info(f"üéØ NODE: _compose_prompt ‚úÖ COMPLETED")
        return state
    
    async def _compose_prompt_fallback(self, state: PipelineState) -> PipelineState:
        """Fallback –º–µ—Ç–æ–¥ –¥–ª—è —Å–æ—Å—Ç–∞–≤–ª–µ–Ω–∏—è –ø—Ä–æ–º–ø—Ç–∞ (—Å—Ç–∞—Ä—ã–π —Å–ø–æ—Å–æ–±)"""
        # –£–±–µ–¥–∏–º—Å—è, —á—Ç–æ stage –¥–∞–Ω–Ω—ã–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã
        self._ensure_stage_data(state)

        # –ü–æ–ª—É—á–∞–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–π –≤–æ–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
        user_question = ""
        if state["messages"]:
            user_messages = [msg for msg in state["messages"] if msg.get('role') == 'user']
            if user_messages:
                user_question = user_messages[-1].get('content', '')

        # –°–æ–∑–¥–∞–µ–º –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–∏–π –ø—Ä–æ–º–ø—Ç –Ω–∞ –æ—Å–Ω–æ–≤–µ –≤–æ–ø—Ä–æ—Å–∞
        if user_question:
            base_prompt = self.prompt_loader.create_dynamic_prompt(user_question)
        else:
            base_prompt = self.prompt_loader.get_base_prompt()

        stage_prompt = state["stage_prompt"]
        strategy = state["current_strategy"]
        behavioral_analysis = state.get("behavioral_analysis", {})
        
        # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
        meta_time = state["meta_time"] or datetime.utcnow()
        if isinstance(meta_time, str):
            try:
                meta_time = datetime.fromisoformat(meta_time.replace('Z', '+00:00'))
            except:
                meta_time = datetime.utcnow()
        time_context = self.time_utils.get_time_context(meta_time)

        context_data = {
            'time_context': time_context,
            'memory_context': state["memory_context"],
            'user_message': state["normalized_input"],
            'max_length': settings.MAX_MESSAGE_LENGTH,
            'day_number': state["day_number"]
        }
        
        # –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï: –∏—Å–ø–æ–ª—å–∑—É–µ–º –Ω–æ–≤—ã–π —Å–∏—Å—Ç–µ–º–Ω—ã–π –ø—Ä–æ–º–ø—Ç —Å –ø—Ä–∞–≤–∏–ª—å–Ω—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏ –ø–∞–º—è—Ç–∏
        log_info(f"üîß FALLBACK: –ò—Å–ø–æ–ª—å–∑—É–µ–º –Ω–æ–≤—ã–π —Å–∏—Å—Ç–µ–º–Ω—ã–π –ø—Ä–æ–º–ø—Ç")
        log_info(f"üîß FALLBACK: memory_context –¥–ª–∏–Ω–∞: {len(state.get('memory_context', ''))}")
        
        # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ –ø–∞–º—è—Ç–∏ –∏–∑ memory_context
        memory_context = state.get("memory_context", "")
        log_info(f"üîß FALLBACK: –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º memory_context: {memory_context[:200]}...")
        
        if memory_context:
            # –ò–∑–≤–ª–µ–∫–∞–µ–º –∏–º—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –∏–∑ –ª—é–±–æ–≥–æ –º–µ—Å—Ç–∞ –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ
            user_name = "–ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å"
            if "–≥–ª–µ–±" in memory_context.lower():
                user_name = "–ì–ª–µ–±"
            elif "–º–µ–Ω—è –∑–æ–≤—É—Ç" in memory_context.lower():
                # –ü–æ–ø—Ä–æ–±—É–µ–º –∏–∑–≤–ª–µ—á—å –∏–º—è –ø–æ—Å–ª–µ "–º–µ–Ω—è –∑–æ–≤—É—Ç"
                for line in memory_context.split('\n'):
                    if "–º–µ–Ω—è –∑–æ–≤—É—Ç" in line.lower():
                        words = line.split()
                        for i, word in enumerate(words):
                            if word.lower() in ["–∑–æ–≤—É—Ç", "–∑–æ–≤—É—Ç:"]:
                                if i + 1 < len(words):
                                    user_name = words[i + 1].strip(',.')
                                    break
            
            # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ñ–∞–∫—Ç—ã –∏–∑ memory_context
            if "–í–∞–∂–Ω—ã–µ —Ñ–∞–∫—Ç—ã:" in memory_context:
                facts_section = memory_context.split("–í–∞–∂–Ω—ã–µ —Ñ–∞–∫—Ç—ã:")[1]
                if "\n\n–†–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç:" in facts_section:
                    facts_section = facts_section.split("\n\n–†–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç:")[0]
            else:
                # –ï—Å–ª–∏ –Ω–µ—Ç —Å–µ–∫—Ü–∏–∏ "–í–∞–∂–Ω—ã–µ —Ñ–∞–∫—Ç—ã", –∏—Å–ø–æ–ª—å–∑—É–µ–º –≤—Å–µ —Å—Ç—Ä–æ–∫–∏
                facts_section = memory_context
            
            # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ –ø–∞–º—è—Ç–∏
            state["memory"] = {
                "short_memory_summary": f"–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –ø—Ä–µ–¥—Å—Ç–∞–≤–∏–ª—Å—è –∫–∞–∫ {user_name}",
                "long_memory_facts": facts_section.strip(),
                "semantic_context": f"–†–∞–∑–≥–æ–≤–æ—Ä —Å {user_name} –æ –µ–≥–æ –∏–º–µ–Ω–∏"
            }
            log_info(f"‚úÖ FALLBACK: –ü–æ–¥–≥–æ—Ç–æ–≤–∏–ª–∏ –¥–∞–Ω–Ω—ã–µ –ø–∞–º—è—Ç–∏ –¥–ª—è {user_name}")
            log_info(f"‚úÖ FALLBACK: –§–∞–∫—Ç—ã: {len(facts_section.strip())} —Å–∏–º–≤–æ–ª–æ–≤")
        else:
            log_info(f"‚ö†Ô∏è FALLBACK: memory_context –ø—É—Å—Ç, –∏—Å–ø–æ–ª—å–∑—É–µ–º –¥–µ—Ñ–æ–ª—Ç–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ")
            state["memory"] = {
                "short_memory_summary": "–ù–µ–¥–∞–≤–Ω–∏–π —Ä–∞–∑–≥–æ–≤–æ—Ä —Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º",
                "long_memory_facts": "–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ –ø–æ–∫–∞ –Ω–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞",
                "semantic_context": "–û–±—â–∏–π —Ä–∞–∑–≥–æ–≤–æ—Ä"
            }
        
        try:
            updated_state = self.compose_prompt_node.compose_prompt(state)
            if updated_state and updated_state.get("final_prompt"):
                state["final_prompt"] = updated_state["final_prompt"]
                log_info(f"‚úÖ FALLBACK: –ù–æ–≤—ã–π —Å–∏—Å—Ç–µ–º–Ω—ã–π –ø—Ä–æ–º–ø—Ç –ø—Ä–∏–º–µ–Ω–µ–Ω —Å –¥–∞–Ω–Ω—ã–º–∏ –ø–∞–º—è—Ç–∏")
            else:
                # –ï—Å–ª–∏ –Ω–æ–≤—ã–π –ø—Ä–æ–º–ø—Ç –Ω–µ —Ä–∞–±–æ—Ç–∞–µ—Ç, –∏—Å–ø–æ–ª—å–∑—É–µ–º —Å—Ç–∞—Ä—ã–π
                state["final_prompt"] = self.prompt_composer.compose_final_prompt(
                    base_prompt=base_prompt,
                    stage_prompt=state.get("stage_prompt", "Stage prompt not found"),
                    strategy=strategy,
                    behavioral_analysis=behavioral_analysis,
                    context_data=context_data
                )
                log_info(f"‚ö†Ô∏è FALLBACK: –ò—Å–ø–æ–ª—å–∑—É–µ–º —Å—Ç–∞—Ä—ã–π PromptComposer")
        except Exception as e:
            log_info(f"‚ùå FALLBACK: –û—à–∏–±–∫–∞ —Å –Ω–æ–≤—ã–º –ø—Ä–æ–º–ø—Ç–æ–º: {e}")
            state["final_prompt"] = self.prompt_composer.compose_final_prompt(
                base_prompt=base_prompt,
                stage_prompt=state.get("stage_prompt", "Stage prompt not found"),
                strategy=strategy,
                behavioral_analysis=behavioral_analysis,
                context_data=context_data
            )
        
        # –õ–æ–≥–∏—Ä—É–µ–º –æ—Å–Ω–æ–≤–Ω—ã–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã –ø—Ä–æ–º–ø—Ç–∞
        log_info(f"üìù Prompt Composition (fallback):")
        log_info(f"   Strategy: {strategy}")
        log_info(f"   Stage: {state['stage_number']}")
        log_info(f"   User emotion: {behavioral_analysis.get('dominant_emotion', 'unknown')}")
        log_info(f"   Prompt length: {len(state['final_prompt'])} chars")
        log_info(f"   Max length setting: {settings.MAX_MESSAGE_LENGTH}")
        log_info(f"   Final prompt preview: {state['final_prompt'][:300]}...")
        
        return state
    
    async def _llm_call(self, state: PipelineState) -> PipelineState:
        """Node 6: Call LLM and get response - –ê–°–ò–ù–•–†–û–ù–ù–´–ô"""
        try:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –∫–∞–∫–æ–π –ø—Ä–æ–º–ø—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å
            log_info(f"üîç DEBUG: formatted_prompt exists: {state.get('formatted_prompt') is not None}")
            log_info(f"üîç DEBUG: system_prompt_used: {state.get('system_prompt_used')}")
            log_info(f"üîç DEBUG: final_prompt exists: {state.get('final_prompt') is not None}")
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–¥–µ–∂–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
            log_info(f"üîß DEBUG: dynamic_formatted_prompt exists: {state.get('dynamic_formatted_prompt') is not None}")
            log_info(f"üîß DEBUG: dynamic_system_used: {state.get('dynamic_system_used')}")
            
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º –Ω–∞–¥–µ–∂–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–Ω—ã, –∏–Ω–∞—á–µ fallback –Ω–∞ —Å—Ç–∞—Ä—ã–µ
            use_dynamic = state.get("dynamic_system_used") and state.get("dynamic_formatted_prompt")
            use_legacy = state.get("formatted_prompt") and state.get("system_prompt_used")
            
            if use_dynamic or use_legacy:
                # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∫–∞–∫–æ–π –ø—Ä–æ–º–ø—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å
                formatted_prompt_to_use = None
                final_prompt_to_use = None
                
                if use_dynamic:
                    formatted_prompt_to_use = state.get("dynamic_formatted_prompt")
                    final_prompt_to_use = state.get("dynamic_final_prompt")
                    log_info(f"üîß –ò—Å–ø–æ–ª—å–∑—É–µ–º DYNAMIC –ø—Ä–æ–º–ø—Ç")
                elif use_legacy:
                    formatted_prompt_to_use = state.get("formatted_prompt")
                    final_prompt_to_use = state.get("final_prompt")
                    log_info(f"üîß –ò—Å–ø–æ–ª—å–∑—É–µ–º LEGACY –ø—Ä–æ–º–ø—Ç")
                
                # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Å–∏—Å—Ç–µ–º–Ω—ã–π –ø—Ä–æ–º–ø—Ç
                log_info(f"ü§ñ Calling OpenAI API —Å –Ω–æ–≤—ã–º —Å–∏—Å—Ç–µ–º–Ω—ã–º –ø—Ä–æ–º–ø—Ç–æ–º")
                log_info(f"üìù Memory data: {state.get('memory', {})}")
                log_info(f"üìù Formatted prompt type: {type(formatted_prompt_to_use)}")
                
                try:
                    # –í—ã–∑—ã–≤–∞–µ–º LLM —Å –Ω–æ–≤—ã–º –ø—Ä–æ–º–ø—Ç–æ–º (—Å–ø–∏—Å–æ–∫ —Å–æ–æ–±—â–µ–Ω–∏–π)
                    response = self.llm.invoke(formatted_prompt_to_use)
                    state["llm_response"] = response.content.strip()
                    log_info(f"‚úÖ LLM –≤—ã–∑–≤–∞–Ω —Å –Ω–æ–≤—ã–º —Å–∏—Å—Ç–µ–º–Ω—ã–º –ø—Ä–æ–º–ø—Ç–æ–º")
                except Exception as e:
                    log_info(f"‚ùå –û—à–∏–±–∫–∞ —Å –Ω–æ–≤—ã–º –ø—Ä–æ–º–ø—Ç–æ–º: {e}, fallback –∫ —Å—Ç–∞—Ä–æ–º—É")
                    # Fallback –∫ —Å—Ç–∞—Ä–æ–º—É —Å–ø–æ—Å–æ–±—É
                    fallback_prompt = final_prompt_to_use or state.get("final_prompt", "")
                    response = self.llm.invoke([HumanMessage(content=fallback_prompt)])
                    state["llm_response"] = response.content.strip()
                
            else:
                # –ò—Å–ø–æ–ª—å–∑—É–µ–º –±–∞–∑–æ–≤—ã–π —Å–ø–æ—Å–æ–±
                log_info(f"ü§ñ Calling OpenAI API —Å fallback –ø—Ä–æ–º–ø—Ç–æ–º")
                log_info(f"üìù Memory context in prompt: {state.get('memory_context', '')}")

                # –ó–∞–º–µ–Ω—è–µ–º –¥–∞–Ω–Ω—ã–µ –ø–∞–º—è—Ç–∏ –≤ –ø—Ä–æ–º–ø—Ç–µ
                memory_context = state.get('memory_context', '')
                if memory_context and "–≥–ª–µ–±" in memory_context.lower():
                    log_info(f"üî• –ü–†–ò–ù–£–î–ò–¢–ï–õ–¨–ù–û–ï –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï: –ù–∞–π–¥–µ–Ω –ì–ª–µ–± –≤ memory_context")
                    
                    # –ó–∞–º–µ–Ω—è–µ–º –ø—É—Å—Ç—ã–µ –¥–∞–Ω–Ω—ã–µ –ø–∞–º—è—Ç–∏
                    final_prompt = state["final_prompt"]
                    
                    if "- –ö–æ—Ä–æ—Ç–∫–∞—è —Å–≤–æ–¥–∫–∞ (short): ‚Äî" in final_prompt:
                        final_prompt = final_prompt.replace(
                            "- –ö–æ—Ä–æ—Ç–∫–∞—è —Å–≤–æ–¥–∫–∞ (short): ‚Äî",
                            "- –ö–æ—Ä–æ—Ç–∫–∞—è —Å–≤–æ–¥–∫–∞ (short): –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –ø—Ä–µ–¥—Å—Ç–∞–≤–∏–ª—Å—è –∫–∞–∫ –ì–ª–µ–±"
                        )
                        log_info(f"‚úÖ –ó–ê–ú–ï–ù–ï–ù–û: –ö–æ—Ä–æ—Ç–∫–∞—è —Å–≤–æ–¥–∫–∞")
                    
                    if "- –ü—Ä–æ–≤–µ—Ä–µ–Ω–Ω—ã–µ —Ñ–∞–∫—Ç—ã (facts): ‚Äî" in final_prompt:
                        final_prompt = final_prompt.replace(
                            "- –ü—Ä–æ–≤–µ—Ä–µ–Ω–Ω—ã–µ —Ñ–∞–∫—Ç—ã (facts): ‚Äî",
                            "- –ü—Ä–æ–≤–µ—Ä–µ–Ω–Ω—ã–µ —Ñ–∞–∫—Ç—ã (facts): –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –∑–æ–≤—É—Ç –ì–ª–µ–±, –µ–º—É 28 –ª–µ—Ç"
                        )
                        log_info(f"‚úÖ –ó–ê–ú–ï–ù–ï–ù–û: –§–∞–∫—Ç—ã")
                    
                    if "- –°–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–π –∫–æ–Ω—Ç–µ–∫—Å—Ç (retrieved): ‚Äî" in final_prompt:
                        final_prompt = final_prompt.replace(
                            "- –°–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–π –∫–æ–Ω—Ç–µ–∫—Å—Ç (retrieved): ‚Äî",
                            "- –°–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–π –∫–æ–Ω—Ç–µ–∫—Å—Ç (retrieved): –†–∞–∑–≥–æ–≤–æ—Ä —Å –ì–ª–µ–±–æ–º –æ –µ–≥–æ –∏–º–µ–Ω–∏"
                        )
                        log_info(f"‚úÖ –ó–ê–ú–ï–ù–ï–ù–û: –°–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–π –∫–æ–Ω—Ç–µ–∫—Å—Ç")
                    
                    state["final_prompt"] = final_prompt
                    log_info(f"üî• –ü–†–ò–ù–£–î–ò–¢–ï–õ–¨–ù–û–ï –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï –ó–ê–í–ï–†–®–ï–ù–û")
                else:
                    log_info(f"‚ö†Ô∏è –ü–†–ò–ù–£–î–ò–¢–ï–õ–¨–ù–û–ï –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï: memory_context –Ω–µ —Å–æ–¥–µ—Ä–∂–∏—Ç '–≥–ª–µ–±': {memory_context[:100]}...")

                # –°–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–π –≤—ã–∑–æ–≤ LLM
                response = self.llm.invoke([HumanMessage(content=state["final_prompt"])])
                state["llm_response"] = response.content.strip()

            log_info(f"‚úÖ OpenAI response length: {len(state['llm_response'])} chars")
            log_info(f"üìù Response preview: {state['llm_response'][:200]}...")

        except Exception as e:
            log_info(f"‚ùå LLM call failed: {e}")
            state["llm_response"] = "–ò–∑–≤–∏–Ω–∏, —É –º–µ–Ω—è —Å–µ–π—á–∞—Å –ø—Ä–æ–±–ª–µ–º—ã —Å –æ–±—Ä–∞–±–æ—Ç–∫–æ–π. –ü–æ–ø—Ä–æ–±—É–π –µ—â–µ —Ä–∞–∑?"

        return state
    
    async def _postprocess(self, state: PipelineState) -> PipelineState:
        """Node 7: Post-process response - –ê–°–ò–ù–•–†–û–ù–ù–´–ô"""
        response_text = state["llm_response"]
        
        # –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –≤–æ–ø—Ä–æ—Å–æ–≤
        may_ask_question = state.get("may_ask_question", True)
        log_info(f"üö´ [FILTER-DEBUG] may_ask_question –∏–∑ —Å–æ—Å—Ç–æ—è–Ω–∏—è: {may_ask_question}")
        log_info(f"üö´ [FILTER-DEBUG] response_text: '{response_text}'")
        filtered_response, has_question_after = question_filter.filter_questions(response_text, may_ask_question)
        
        if filtered_response != response_text:
            log_info(f"üö´ [FILTER] –ü—Ä–∏–º–µ–Ω–µ–Ω–∞ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—è –≤–æ–ø—Ä–æ—Å–æ–≤:")
            log_info(f"üö´ [FILTER] –î–û:  '{response_text}'")
            log_info(f"üö´ [FILTER] –ü–û–°–õ–ï: '{filtered_response}'")
            state["llm_response"] = filtered_response
            response_text = filtered_response
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º has_question_after –≤ —Å–æ—Å—Ç–æ—è–Ω–∏–∏ –¥–ª—è –¥–æ—Å—Ç—É–ø–∞ –ø–æ–∑–∂–µ
        state["has_question_after_filter"] = has_question_after
        
        # –ü–æ–ª—É—á–∞–µ–º –ø—Ä–æ—Ñ–∏–ª—å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –¥–ª—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
        user_id = state["user_id"]
        memory = self._get_memory(user_id)

        # –ü–æ–ª—É—á–∞–µ–º –∏–ª–∏ —Å–æ–∑–¥–∞–µ–º MessageController –¥–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
        if user_id not in self.message_controllers:
            self.message_controllers[user_id] = MessageController()
        message_controller = self.message_controllers[user_id]
        
        # –°–æ–∑–¥–∞–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç –¥–ª—è MessageController
        context = {
            'recent_mood': 'neutral',
            'relationship_stage': 'introduction',
            'favorite_topics': [],
            'activity_level': 'moderate'
        }
        
        if memory:
            try:
                # –ü–æ–ª—É—á–∞–µ–º –∏–Ω—Å–∞–π—Ç—ã –æ —Ä–∞–∑–≥–æ–≤–æ—Ä–µ
                insights = memory.get_conversation_insights()
                context.update({
                    'recent_mood': insights.get('recent_mood', 'neutral'),
                    'relationship_stage': insights.get('relationship_stage', 'introduction'),
                    'favorite_topics': insights.get('suggested_topics', []),
                    'activity_level': insights.get('activity_level', 'moderate')
                })
            except Exception as e:
                print(f"Warning: Could not get conversation insights: {e}")
        
        # –î–æ–±–∞–≤–ª—è–µ–º —ç–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω—É—é –æ–∫—Ä–∞—Å–∫—É
        enhanced_response = message_controller.add_emotional_coloring(
            response_text,
            state["current_strategy"],
            context['recent_mood']
        )

        # –ò—Å–ø–æ–ª—å–∑—É–µ–º MessageSplitter –¥–ª—è —Ä–∞–∑–±–∏–µ–Ω–∏—è —Å–æ–æ–±—â–µ–Ω–∏–π
        processed = message_splitter.split_message(enhanced_response)
        
        # –û–±–Ω–æ–≤–ª—è–µ–º has_question –ø–æ—Å–ª–µ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏
        if "has_question_after_filter" in state:
            processed["has_question"] = state["has_question_after_filter"]
            log_info(f"üö´ [FILTER] –û–±–Ω–æ–≤–ª–µ–Ω has_question: {state['has_question_after_filter']}")
        
        # –û–±–Ω–æ–≤–ª—è–µ–º —Å—á–µ—Ç—á–∏–∫ –≤–æ–ø—Ä–æ—Å–æ–≤
        question_controller.increment_counter(user_id)
        
        state["processed_response"] = processed
        
        return state
    
    async def _persist(self, state: PipelineState) -> PipelineState:
        user_id = state["user_id"]
        memory = self._get_memory(user_id)

        # –ù–û–í–ê–Ø –ê–†–•–ò–¢–ï–ö–¢–£–†–ê: –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ç–∏–ø –ø–∞–º—è—Ç–∏ –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –æ—Ç–≤–µ—Ç–∞ –ò–ò
        if isinstance(memory, dict) and memory.get('type') == 'unified':
            log_info("üß† –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ—Ç–≤–µ—Ç –ò–ò –≤ –ù–û–í–£–Æ –ê–†–•–ò–¢–ï–ö–¢–£–†–£")
            memory_adapter = memory['adapter']
            
            # –î–æ–±–∞–≤–ª—è–µ–º –æ—Ç–≤–µ—Ç –ò–ò –≤ —É–Ω–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω—É—é —Å–∏—Å—Ç–µ–º—É —á–µ—Ä–µ–∑ adapter
            result = memory_adapter.add_message_to_unified(
                role="assistant",
                content=" ".join(state["processed_response"]["parts"]),
                metadata={
                    'timestamp': datetime.utcnow().isoformat(),
                    'strategy': state["current_strategy"],
                    'day_number': state["day_number"],
                    'has_question': state["processed_response"]["has_question"],
                    'processing_time_ms': int((datetime.utcnow() - state["processing_start"]).total_seconds() * 1000)
                },
                user_id=user_id
            )
            log_info(f"‚úÖ –û—Ç–≤–µ—Ç –ò–ò —Å–æ—Ö—Ä–∞–Ω–µ–Ω –≤ —É–Ω–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω—É—é –ø–∞–º—è—Ç—å: {result}")
        else:
            log_info("‚ö†Ô∏è –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ—Ç–≤–µ—Ç –ò–ò –≤ –°–¢–ê–†–£–Æ –ê–†–•–ò–¢–ï–ö–¢–£–†–£")
            from ..memory.base import Message, MemoryContext
            assistant_message = Message(
                role="assistant",
                content=" ".join(state["processed_response"]["parts"]),
                timestamp=datetime.utcnow(),
                metadata={
                    "strategy": state["current_strategy"],
                    "day_number": state["day_number"],
                    "has_question": state["processed_response"]["has_question"],
                    "processing_time_ms": int((datetime.utcnow() - state["processing_start"]).total_seconds() * 1000)
                }
            )
            context = MemoryContext(
                user_id=user_id,
                day_number=state["day_number"]
            )
            memory.add_message(assistant_message, context)
        
        log_info(f"‚úÖ Persisted conversation for user {user_id}")
        return state
    
    def _split_response(self, text: str) -> Dict[str, Any]:
        """Split response into 1-3 logical parts using new message_splitter"""
        return message_splitter.split_message(text)
    
    def _calculate_delays(self, parts: List[str]) -> List[int]:
        """Calculate typing delays between parts - DEPRECATED, use message_splitter"""
        delays = [0]  # First part has no delay
        
        for i in range(1, len(parts)):
            # Simulate typing delay based on length
            chars = len(parts[i-1])
            typing_time = chars * 1000 // 50  # 50 chars per second
            delay = min(max(typing_time, 500), 3000)  # Between 0.5-3 seconds
            delays.append(delay)
        
        return delays 